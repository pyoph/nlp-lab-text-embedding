{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyoph/nlp-lab-text-embedding/blob/main/Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1YhFD09hf4n"
      },
      "source": [
        "#  NLP-lab :  Plongements de mots (word embeddings)\n",
        "\n",
        "                                            Christopher Kermorvant\n",
        "\n",
        "                            “The meaning of a word can be inferred by the company it keeps”\n",
        "\n",
        "Dans cette série d'exercices, nous allons explorer  trois  plongements (embeddings) de mots :\n",
        "\n",
        "*  [Collobert & Weston](http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf) https://ronan.collobert.com/senna/\n",
        "* [GloVe](https://nlp.stanford.edu/projects/glove/)\n",
        "* [BERT](https://huggingface.co/bert-base-uncased)\n",
        "\n",
        "   \n",
        "Pour les deux premiers, nous examinerons les mots les plus proches et visualiserons leurs positions dans l'espaces après réduction de dimension. Puis nous procéderons à des [évaluations](https://arxiv.org/pdf/1801.09536.pdf) qualitatives et intrinsèques des embeddings.\n",
        "\n",
        "Enfin nous étudierons les raisonnements par analogies que l'on peut conduire par l'arithmétique sur les embeddings (et leurs biais).\n",
        "\n",
        "Pour BERT, nous étudierons la représentation d'un mot polysémique en fonction de son contexte.\n",
        "\n",
        "Dans le code déjà fourni, ajouter votre code à l'endroit indiqué par `YOUR CODE HERE`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TeWgBM5Hhf4o"
      },
      "outputs": [],
      "source": [
        "# basic imports\n",
        "import os\n",
        "\n",
        "# disable warnings for libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# configure logger\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
        "logger = logging.getLogger(__name__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fstorage.teklia.com%2Fshared%2Fdeepnlp-labs%2Fcollobert_embeddings.txt.zip\n",
        "!unzip corgiredirector?site=https:%2F%2Fstorage.teklia.com%2Fshared%2Fdeepnlp-labs%2Fcollobert_embeddings.txt.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPFU1oHbphun",
        "outputId": "a6a87fef-5093-4363-adff-f2cd0fe7c723"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  corgiredirector?site=https:%2F%2Fstorage.teklia.com%2Fshared%2Fdeepnlp-labs%2Fcollobert_embeddings.txt.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of corgiredirector?site=https:%2F%2Fstorage.teklia.com%2Fshared%2Fdeepnlp-labs%2Fcollobert_embeddings.txt.zip or\n",
            "        corgiredirector?site=https:%2F%2Fstorage.teklia.com%2Fshared%2Fdeepnlp-labs%2Fcollobert_embeddings.txt.zip.zip, and cannot find corgiredirector?site=https:%2F%2Fstorage.teklia.com%2Fshared%2Fdeepnlp-labs%2Fcollobert_embeddings.txt.zip.ZIP, period.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL5FQatRhf4p"
      },
      "source": [
        "## 1. Les fichiers d'embeddings pré-entraînés\n",
        "\n",
        "Téléchargez dans `data` les fichiers contenant les embeddings :\n",
        "* Collobert (taille 50) : [collobert_embeddings.txt.zip](https://storage.teklia.com/shared/deepnlp-labs/collobert_embeddings.txt.zip) qui contient les vecteurs d'embeddings  et [collobert_words.lst](https://storage.teklia.com/shared/deepnlp-labs/collobert_words.lst) qui contient les mots associés;\n",
        "* Glove (taille 50):  [glove.6B.50d.txt.zip](https://storage.teklia.com/shared/deepnlp-labs/glove.6B.50d.txt.zip) 67 618 Kb qui contient à la fois les vecteurs et les mots.\n",
        "\n",
        "Il faut décompresser les fichiers pour pouvoir les charger.\n",
        "\n",
        "N'hésitez pas à ouvrir les fichiers pour voir ce qu'ils contiennent (c'est parfois surprennant).\n",
        "\n",
        "#### Question :\n",
        ">* Donner la taille des fichiers d'embeddings avant unzip\n",
        "embeddings.txt.zip 23,7 Mo\n",
        "(https://storage.teklia.com/shared/deepnlp-labs/glove.6B.50d.txt.zip) 67 618 Kb\n",
        ">* En explorant le contenu des fichiers d'embedding, donner le nombre de mots pour lesquels ces fichiers fournissent des embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdXi61cYhf4q"
      },
      "source": [
        "## 2. Exploration des embeddings\n",
        "\n",
        "### Liste des mots les plus proches\n",
        "\n",
        "L'objectif de cet exercice est de lister les mots les plus proches d'un mot donné pour l'embeddings Collobert. Dans un premier temps, nous allons charger les vecteurs de l'embedding Collobert dans un array numpy et les mots associés dans une liste python. Ensuite, nous utiliserons la structure de données [KDTree de scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html) pour faire une recherche rapide des vecteurs les plus proches d'une série de mots.\n",
        "\n",
        "### Chargement des embeddings\n",
        "\n",
        "#### Question :\n",
        ">* charger les vecteurs d'embeddings à partir du fichier `data/collobert_embeddings.txt` en utilisant la fonction numpy [genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html)\n",
        ">* charger dans une liste python les mots associés aux vecteurs à partir du fichier `data/collobert_words.lst` (avec `open()` et `readlines()`)\n",
        ">* vérifiez que les tailles sont correctes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XVfKxtBShf4q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "fichier = 'collobert_embeddings.txt'\n",
        "\n",
        "data = np.genfromtxt(fichier)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fichier_mots = 'collobert_words.lst'\n",
        "\n",
        "# Ouvrir le fichier en mode lecture\n",
        "with open(fichier_mots, 'r', encoding='utf-8') as fichier:\n",
        "    # Lire toutes les lignes du fichier\n",
        "    lignes = fichier.readlines()\n",
        "\n",
        "# Supprimer les sauts de ligne et créer une liste de mots\n",
        "mots = [ligne.strip() for ligne in lignes]\n",
        "len(mots)\n",
        "# Afficher la liste de mots\n",
        "#print(mots)"
      ],
      "metadata": {
        "id": "ieZDcp6bkcyl",
        "outputId": "53df7052-4cee-4329-d765-c8207826d784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1VmuYXEpj10s",
        "outputId": "8c4eca50-9037-4443-f6b7-9e90841ce327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7Sj4nRGhf4q"
      },
      "source": [
        "Les arbres KD (KD tree) sont une structure de données très efficace pour stocker de grands ensemble de points dans une espace multi-dimensionnel et faire des recherches très efficaces de plus proches voisins.\n",
        "\n",
        "#### Question\n",
        "> * Initialisez la structure de [KDTree](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html) avec les vecteurs d'embeddings de Collobert\n",
        "> * En utilisant la fonction [tree.query](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.query.html#scipy.spatial.KDTree.query), afficher les 5 mots les plus proches des mots suivants : 'mother', 'computer', 'dentist', 'war', 'president', 'secretary', 'nurse'\n",
        "     * *Indice : vous pouvez utiliser la fonction `collobert_words.index(w)` pour obtenir l'indice d'un mot dans la liste des mots*\n",
        "> * Créer une liste `words_plus_neighbors` contenant les mots et tous leurs voisins (pour la question suivante)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Charger les vecteurs d'embeddings à partir d'un fichier (remplacez le chemin par le vôtre)\n",
        "embedding_file = 'collobert_embeddings.txt'\n",
        "\n",
        "# Charger les vecteurs en tant que tableau numpy\n",
        "embeddings = np.loadtxt(embedding_file)\n",
        "\n",
        "# Initialiser la structure de KDTree avec les vecteurs d'embeddings\n",
        "kdtree = spatial.KDTree(embeddings)\n",
        "\n",
        "# Liste des mots associés aux vecteurs (à partir du fichier collobert_words.lst)\n",
        "mots_file = 'collobert_words.lst'\n",
        "with open(mots_file, 'r', encoding='utf-8') as file:\n",
        "    mots = [line.strip() for line in file.readlines()]\n",
        "\n",
        "# Mots à rechercher\n",
        "mots_a_rechercher = ['mother', 'computer', 'dentist', 'war', 'president', 'secretary', 'nurse']\n",
        "words_plus_neighbors = []\n",
        "\n",
        "# Effectuer la recherche pour chaque mot\n",
        "for mot in mots_a_rechercher:\n",
        "    # Vérifier si le mot est dans la liste\n",
        "    if mot in mots:\n",
        "        # Trouver les indices des 5 mots les plus proches dans l'arbre KD\n",
        "        indices_proches = kdtree.query(embeddings[mots.index(mot)], k=6)[1][1:]\n",
        "\n",
        "        # Afficher les résultats\n",
        "        mots_proches = [mots[indice] for indice in indices_proches]\n",
        "        print(f\"Les 5 mots les plus proches de '{mot}': {mots_proches}\")\n",
        "        neighbors = [mots[indice] for indice in indices_proches]\n",
        "\n",
        "        words_plus_neighbors.append((mot, neighbors))\n",
        "\n",
        "    else:\n",
        "        # Gérer le cas où le mot n'est pas dans la liste\n",
        "        print(f\"Le mot '{mot}' n'est pas présent dans la liste des mots.\")\n",
        "\n",
        "\n",
        "# Afficher la liste words_plus_neighbors\n",
        "for item in words_plus_neighbors:\n",
        "    print(f\"Mot: {item[0]}, Voisins: {item[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "PJCeKA4ZtG10",
        "outputId": "673844f4-7d2e-4218-f987-f942bbde33a1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les 5 mots les plus proches de 'mother': ['daughter', 'wife', 'father', 'husband', 'son']\n",
            "Les 5 mots les plus proches de 'computer': ['laptop', 'multimedia', 'desktop', 'software', 'wiki']\n",
            "Les 5 mots les plus proches de 'dentist': ['pharmacist', 'midwife', 'physician', 'housekeeper', 'veterinarian']\n",
            "Les 5 mots les plus proches de 'war': ['revolution', 'death', 'court', 'independence', 'history']\n",
            "Les 5 mots les plus proches de 'president': ['governor', 'chairman', 'mayor', 'secretary', 'senator']\n",
            "Les 5 mots les plus proches de 'secretary': ['minister', 'treasurer', 'chairman', 'commissioner', 'undersecretary']\n",
            "Les 5 mots les plus proches de 'nurse': ['physician', 'veterinarian', 'dentist', 'surgeon', 'midwife']\n",
            "Mot: mother, Voisins: ['daughter', 'wife', 'father', 'husband', 'son']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'numpy.ndarray' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-d3d0b0fe738a>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_plus_neighbors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mot: {item[0]}, Voisins: {item[1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Downloading NeuroImaging datasets: utility functions\n",
        "\"\"\"\n",
        "import os\n",
        "import numpy as np\n",
        "import collections.abc\n",
        "import contextlib\n",
        "import fnmatch\n",
        "import hashlib\n",
        "import pickle\n",
        "import shutil\n",
        "import time\n",
        "import sys\n",
        "import tarfile\n",
        "import urllib\n",
        "import warnings\n",
        "import zipfile\n",
        "import json\n",
        "\n",
        "import requests\n",
        "\n",
        "#from .._utils import fill_doc\n",
        "\n",
        "_REQUESTS_TIMEOUT = (15.1, 61)\n",
        "\n",
        "\n",
        "def md5_hash(string):\n",
        "    m = hashlib.md5()\n",
        "    m.update(string.encode('utf-8'))\n",
        "    return m.hexdigest()\n",
        "\n",
        "\n",
        "def _format_time(t):\n",
        "    if t > 60:\n",
        "        return \"%4.1fmin\" % (t / 60.)\n",
        "    else:\n",
        "        return \" %5.1fs\" % (t)\n",
        "\n",
        "\n",
        "def _md5_sum_file(path):\n",
        "    \"\"\" Calculates the MD5 sum of a file.\n",
        "    \"\"\"\n",
        "    with open(path, 'rb') as f:\n",
        "        m = hashlib.md5()\n",
        "        while True:\n",
        "            data = f.read(8192)\n",
        "            if not data:\n",
        "                break\n",
        "            m.update(data)\n",
        "    return m.hexdigest()\n",
        "\n",
        "\n",
        "def _read_md5_sum_file(path):\n",
        "    \"\"\" Reads a MD5 checksum file and returns hashes as a dictionary.\n",
        "    \"\"\"\n",
        "    with open(path, \"r\") as f:\n",
        "        hashes = {}\n",
        "        while True:\n",
        "            line = f.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            h, name = line.rstrip().split('  ', 1)\n",
        "            hashes[name] = h\n",
        "    return hashes\n",
        "\n",
        "\n",
        "def readlinkabs(link):\n",
        "    \"\"\"\n",
        "    Return an absolute path for the destination\n",
        "    of a symlink\n",
        "    \"\"\"\n",
        "    path = os.readlink(link)\n",
        "    if os.path.isabs(path):\n",
        "        return path\n",
        "    return os.path.join(os.path.dirname(link), path)\n",
        "\n",
        "\n",
        "def _chunk_report_(bytes_so_far, total_size, initial_size, t0):\n",
        "    \"\"\"Show downloading percentage.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    bytes_so_far : int\n",
        "        Number of downloaded bytes.\n",
        "\n",
        "    total_size : int\n",
        "        Total size of the file (may be 0/None, depending on download method).\n",
        "\n",
        "    t0 : int\n",
        "        The time in seconds (as returned by time.time()) at which the\n",
        "        download was resumed / started.\n",
        "\n",
        "    initial_size : int\n",
        "        If resuming, indicate the initial size of the file.\n",
        "        If not resuming, set to zero.\n",
        "\n",
        "    \"\"\"\n",
        "    if not total_size:\n",
        "        sys.stderr.write(\"\\rDownloaded %d of ? bytes.\" % (bytes_so_far))\n",
        "\n",
        "    else:\n",
        "        # Estimate remaining download time\n",
        "        total_percent = float(bytes_so_far) / total_size\n",
        "\n",
        "        current_download_size = bytes_so_far - initial_size\n",
        "        bytes_remaining = total_size - bytes_so_far\n",
        "        dt = time.time() - t0\n",
        "        download_rate = current_download_size / max(1e-8, float(dt))\n",
        "        # Minimum rate of 0.01 bytes/s, to avoid dividing by zero.\n",
        "        time_remaining = bytes_remaining / max(0.01, download_rate)\n",
        "\n",
        "        # Trailing whitespace is to erase extra char when message length\n",
        "        # varies\n",
        "        sys.stderr.write(\n",
        "            \"\\rDownloaded %d of %d bytes (%.1f%%, %s remaining)\"\n",
        "            % (bytes_so_far, total_size, total_percent * 100,\n",
        "               _format_time(time_remaining)))\n",
        "\n",
        "\n",
        "\n",
        "def _chunk_read_(response, local_file, chunk_size=8192, report_hook=None,\n",
        "                 initial_size=0, total_size=None, verbose=1):\n",
        "    \"\"\"Download a file chunk by chunk and show advancement\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    response : urllib.response.addinfourl\n",
        "        Response to the download request in order to get file size.\n",
        "\n",
        "    local_file : file\n",
        "        Hard disk file where data should be written.\n",
        "\n",
        "    chunk_size : int, optional\n",
        "        Size of downloaded chunks. Default=8192.\n",
        "\n",
        "    report_hook : bool, optional\n",
        "        Whether or not to show downloading advancement. Default: None\n",
        "\n",
        "    initial_size : int, optional\n",
        "        If resuming, indicate the initial size of the file.\n",
        "        Default=0.\n",
        "\n",
        "    total_size : int, optional\n",
        "        Expected final size of download (None means it is unknown).\n",
        "    %(verbose)s\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    data : string\n",
        "        The downloaded file.\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if total_size is None:\n",
        "            total_size = response.headers.get('Content-Length').strip()\n",
        "        total_size = int(total_size) + initial_size\n",
        "    except Exception as e:\n",
        "        if verbose > 2:\n",
        "            print(\"Warning: total size could not be determined.\")\n",
        "            if verbose > 3:\n",
        "                print(\"Full stack trace: %s\" % e)\n",
        "        total_size = None\n",
        "    bytes_so_far = initial_size\n",
        "\n",
        "    t0 = time_last_display = time.time()\n",
        "    for chunk in response.iter_content(chunk_size):\n",
        "        bytes_so_far += len(chunk)\n",
        "        time_last_read = time.time()\n",
        "        if (report_hook and\n",
        "                # Refresh report every second or when download is\n",
        "                # finished.\n",
        "                (time_last_read > time_last_display + 1. or not chunk)):\n",
        "            _chunk_report_(bytes_so_far,\n",
        "                           total_size, initial_size, t0)\n",
        "            time_last_display = time_last_read\n",
        "        if chunk:\n",
        "            local_file.write(chunk)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "\n",
        "def get_data_dirs(data_dir=None):\n",
        "    \"\"\"Returns the directories in which nilearn looks for data.\n",
        "\n",
        "    This is typically useful for the end-user to check where the data is\n",
        "    downloaded and stored.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    %(data_dir)s\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    paths : list of strings\n",
        "        Paths of the dataset directories.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    This function retrieves the datasets directories using the following\n",
        "    priority :\n",
        "\n",
        "    1. defaults system paths\n",
        "    2. the keyword argument data_dir\n",
        "    3. the global environment variable NILEARN_SHARED_DATA\n",
        "    4. the user environment variable NILEARN_DATA\n",
        "    5. nilearn_data in the user home folder\n",
        "\n",
        "    \"\"\"\n",
        "    # We build an array of successive paths by priority\n",
        "    # The boolean indicates if it is a pre_dir: in that case, we won't add the\n",
        "    # dataset name to the path.\n",
        "    paths = []\n",
        "\n",
        "    # Check data_dir which force storage in a specific location\n",
        "    if data_dir is not None:\n",
        "        paths.extend(str(data_dir).split(os.pathsep))\n",
        "\n",
        "    # If data_dir has not been specified, then we crawl default locations\n",
        "    if data_dir is None:\n",
        "        global_data = os.getenv('NILEARN_SHARED_DATA')\n",
        "        if global_data is not None:\n",
        "            paths.extend(global_data.split(os.pathsep))\n",
        "\n",
        "        local_data = os.getenv('NILEARN_DATA')\n",
        "        if local_data is not None:\n",
        "            paths.extend(local_data.split(os.pathsep))\n",
        "\n",
        "        paths.append(os.path.expanduser('~/nilearn_data'))\n",
        "    return paths\n",
        "\n",
        "\n",
        "\n",
        "def _get_dataset_dir(dataset_name, data_dir=None, default_paths=None,\n",
        "                     verbose=1):\n",
        "    \"\"\"Creates if necessary and returns data directory of given dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset_name : string\n",
        "        The unique name of the dataset.\n",
        "    %(data_dir)s\n",
        "    default_paths : list of string, optional\n",
        "        Default system paths in which the dataset may already have been\n",
        "        installed by a third party software. They will be checked first.\n",
        "    %(verbose)s\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    data_dir : string\n",
        "        Path of the given dataset directory.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    This function retrieves the datasets directory (or data directory) using\n",
        "    the following priority :\n",
        "\n",
        "    1. defaults system paths\n",
        "    2. the keyword argument data_dir\n",
        "    3. the global environment variable NILEARN_SHARED_DATA\n",
        "    4. the user environment variable NILEARN_DATA\n",
        "    5. nilearn_data in the user home folder\n",
        "\n",
        "    \"\"\"\n",
        "    paths = []\n",
        "    # Search possible data-specific system paths\n",
        "    if default_paths is not None:\n",
        "        for default_path in default_paths:\n",
        "            paths.extend([\n",
        "                (d, True)\n",
        "                for d in str(default_path).split(os.pathsep)]\n",
        "            )\n",
        "\n",
        "    paths.extend([(d, False) for d in get_data_dirs(data_dir=data_dir)])\n",
        "\n",
        "    if verbose > 2:\n",
        "        print('Dataset search paths: %s' % paths)\n",
        "\n",
        "    # Check if the dataset exists somewhere\n",
        "    for path, is_pre_dir in paths:\n",
        "        if not is_pre_dir:\n",
        "            path = os.path.join(path, dataset_name)\n",
        "        if os.path.islink(path):\n",
        "            # Resolve path\n",
        "            path = readlinkabs(path)\n",
        "        if os.path.exists(path) and os.path.isdir(path):\n",
        "            if verbose > 1:\n",
        "                print('\\nDataset found in %s\\n' % path)\n",
        "            return path\n",
        "\n",
        "    # If not, create a folder in the first writeable directory\n",
        "    errors = []\n",
        "    for (path, is_pre_dir) in paths:\n",
        "        if not is_pre_dir:\n",
        "            path = os.path.join(path, dataset_name)\n",
        "        if not os.path.exists(path):\n",
        "            try:\n",
        "                os.makedirs(path)\n",
        "                if verbose > 0:\n",
        "                    print('\\nDataset created in %s\\n' % path)\n",
        "                return path\n",
        "            except Exception as exc:\n",
        "                short_error_message = getattr(exc, 'strerror', str(exc))\n",
        "                errors.append('\\n -{0} ({1})'.format(\n",
        "                    path, short_error_message))\n",
        "\n",
        "    raise OSError('Nilearn tried to store the dataset in the following '\n",
        "                  'directories, but:' + ''.join(errors))\n",
        "\n",
        "\n",
        "# The functions _is_within_directory and _safe_extract were implemented in\n",
        "# https://github.com/nilearn/nilearn/pull/3391 to address a directory\n",
        "# traversal vulnerability https://github.com/advisories/GHSA-gw9q-c7gh-j9vm\n",
        "def _is_within_directory(directory, target):\n",
        "    abs_directory = os.path.abspath(directory)\n",
        "    abs_target = os.path.abspath(target)\n",
        "\n",
        "    prefix = os.path.commonprefix([abs_directory, abs_target])\n",
        "\n",
        "    return prefix == abs_directory\n",
        "\n",
        "\n",
        "def _safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
        "    for member in tar.getmembers():\n",
        "        member_path = os.path.join(path, member.name)\n",
        "        if not _is_within_directory(path, member_path):\n",
        "            raise Exception(\"Attempted Path Traversal in Tar File\")\n",
        "\n",
        "    tar.extractall(path, members, numeric_owner=numeric_owner)\n",
        "\n",
        "\n",
        "\n",
        "def _uncompress_file(file_, delete_archive=True, verbose=1):\n",
        "    \"\"\"Uncompress files contained in a data_set.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_ : string\n",
        "        Path of file to be uncompressed.\n",
        "\n",
        "    delete_archive : bool, optional\n",
        "        Whether or not to delete archive once it is uncompressed.\n",
        "        Default=True.\n",
        "    %(verbose)s\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    This handles zip, tar, gzip and bzip files only.\n",
        "\n",
        "    \"\"\"\n",
        "    if verbose > 0:\n",
        "        sys.stderr.write('Extracting data from %s...' % file_)\n",
        "    data_dir = os.path.dirname(file_)\n",
        "    # We first try to see if it is a zip file\n",
        "    try:\n",
        "        filename, ext = os.path.splitext(file_)\n",
        "        with open(file_, \"rb\") as fd:\n",
        "            header = fd.read(4)\n",
        "        processed = False\n",
        "        if zipfile.is_zipfile(file_):\n",
        "            z = zipfile.ZipFile(file_)\n",
        "            z.extractall(path=data_dir)\n",
        "            z.close()\n",
        "            if delete_archive:\n",
        "                os.remove(file_)\n",
        "            file_ = filename\n",
        "            processed = True\n",
        "        elif ext == '.gz' or header.startswith(b'\\x1f\\x8b'):\n",
        "            import gzip\n",
        "            if ext == '.tgz':\n",
        "                filename = filename + '.tar'\n",
        "            elif ext == '':\n",
        "                # We rely on the assumption that gzip files have an extension\n",
        "                shutil.move(file_, file_ + '.gz')\n",
        "                file_ = file_ + '.gz'\n",
        "            with gzip.open(file_) as gz:\n",
        "                with open(filename, 'wb') as out:\n",
        "                    shutil.copyfileobj(gz, out, 8192)\n",
        "            # If file is .tar.gz, this will be handled in the next case\n",
        "            if delete_archive:\n",
        "                os.remove(file_)\n",
        "            file_ = filename\n",
        "            processed = True\n",
        "        if os.path.isfile(file_) and tarfile.is_tarfile(file_):\n",
        "            with contextlib.closing(tarfile.open(file_, \"r\")) as tar:\n",
        "                _safe_extract(tar, path=data_dir)\n",
        "            if delete_archive:\n",
        "                os.remove(file_)\n",
        "            processed = True\n",
        "        if not processed:\n",
        "            raise IOError(\n",
        "                    \"[Uncompress] unknown archive file format: %s\" % file_)\n",
        "\n",
        "        if verbose > 0:\n",
        "            sys.stderr.write('.. done.\\n')\n",
        "    except Exception as e:\n",
        "        if verbose > 0:\n",
        "            print('Error uncompressing file: %s' % e)\n",
        "        raise\n",
        "\n",
        "\n",
        "def _filter_column(array, col, criteria):\n",
        "    \"\"\"Return index array matching criteria\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    array : numpy array with columns\n",
        "        Array in which data will be filtered.\n",
        "\n",
        "    col : string\n",
        "        Name of the column.\n",
        "\n",
        "    criteria : integer (or float), pair of integers, string or list of these\n",
        "        if integer, select elements in column matching integer\n",
        "        if a tuple, select elements between the limits given by the tuple\n",
        "        if a string, select elements that match the string\n",
        "\n",
        "    \"\"\"\n",
        "    # Raise an error if the column does not exist. This is the only way to\n",
        "    # test it across all possible types (pandas, recarray...)\n",
        "    try:\n",
        "        array[col]\n",
        "    except:\n",
        "        raise KeyError('Filtering criterion %s does not exist' % col)\n",
        "\n",
        "    if (not isinstance(criteria, str) and\n",
        "        not isinstance(criteria, bytes) and\n",
        "        not isinstance(criteria, tuple) and\n",
        "            isinstance(criteria, collections.abc.Iterable)):\n",
        "        filter = np.zeros(array.shape[0], dtype=bool)\n",
        "        for criterion in criteria:\n",
        "            filter = np.logical_or(filter,\n",
        "                                   _filter_column(array, col, criterion))\n",
        "        return filter\n",
        "\n",
        "    if isinstance(criteria, tuple):\n",
        "        if len(criteria) != 2:\n",
        "            raise ValueError(\"An interval must have 2 values\")\n",
        "        if criteria[0] is None:\n",
        "            return array[col] <= criteria[1]\n",
        "        if criteria[1] is None:\n",
        "            return array[col] >= criteria[0]\n",
        "        filter = array[col] <= criteria[1]\n",
        "        return np.logical_and(filter, array[col] >= criteria[0])\n",
        "\n",
        "    # Handle strings with different encodings\n",
        "    if isinstance(criteria, (str, bytes)):\n",
        "        criteria = np.array(criteria).astype(array[col].dtype)\n",
        "\n",
        "    return array[col] == criteria\n",
        "\n",
        "\n",
        "def _filter_columns(array, filters, combination='and'):\n",
        "    \"\"\"Return indices of recarray entries that match criteria.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    array : numpy array with columns\n",
        "        Array in which data will be filtered.\n",
        "\n",
        "    filters : list of criteria\n",
        "        See _filter_column.\n",
        "\n",
        "    combination : string {'and', 'or'}, optional\n",
        "        String describing the combination operator. Possible values are \"and\"\n",
        "        and \"or\". Default='and'.\n",
        "\n",
        "    \"\"\"\n",
        "    if combination == 'and':\n",
        "        fcomb = np.logical_and\n",
        "        mask = np.ones(array.shape[0], dtype=bool)\n",
        "    elif combination == 'or':\n",
        "        fcomb = np.logical_or\n",
        "        mask = np.zeros(array.shape[0], dtype=bool)\n",
        "    else:\n",
        "        raise ValueError('Combination mode not known: %s' % combination)\n",
        "\n",
        "    for column in filters:\n",
        "        mask = fcomb(mask, _filter_column(array, column, filters[column]))\n",
        "    return mask\n",
        "\n",
        "\n",
        "class _NaiveFTPAdapter(requests.adapters.BaseAdapter):\n",
        "    def send(self, request, timeout=None, **kwargs):\n",
        "        try:\n",
        "            timeout, _ = timeout\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            data = urllib.request.urlopen(request.url, timeout=timeout)\n",
        "        except Exception as e:\n",
        "            raise requests.RequestException(e.reason)\n",
        "        data.release_conn = data.close\n",
        "        resp = requests.Response()\n",
        "        resp.url = data.geturl()\n",
        "        resp.status_code = data.getcode() or 200\n",
        "        resp.raw = data\n",
        "        resp.headers = dict(data.info().items())\n",
        "        return resp\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "def _fetch_file(url, data_dir, resume=True, overwrite=False,\n",
        "                md5sum=None, username=None, password=None,\n",
        "                verbose=1, session=None):\n",
        "    \"\"\"Load requested file, downloading it if needed or requested.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    %(url)s\n",
        "    %(data_dir)s\n",
        "    %(resume)s\n",
        "    overwrite : bool, optional\n",
        "        If true and file already exists, delete it. Default=False.\n",
        "\n",
        "    md5sum : string, optional\n",
        "        MD5 sum of the file. Checked if download of the file is required.\n",
        "\n",
        "    username : string, optional\n",
        "        Username used for basic HTTP authentication.\n",
        "\n",
        "    password : string, optional\n",
        "        Password used for basic HTTP authentication.\n",
        "    %(verbose)s\n",
        "    session : requests.Session, optional\n",
        "        Session to use to send requests.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    files : string\n",
        "        Absolute path of downloaded file.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    If, for any reason, the download procedure fails, all downloaded files are\n",
        "    removed.\n",
        "\n",
        "    \"\"\"\n",
        "    if session is None:\n",
        "        with requests.Session() as session:\n",
        "            session.mount(\"ftp:\", _NaiveFTPAdapter())\n",
        "            return _fetch_file(\n",
        "                url, data_dir, resume=resume, overwrite=overwrite,\n",
        "                md5sum=md5sum, username=username, password=password,\n",
        "                verbose=verbose, session=session)\n",
        "    # Determine data path\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "\n",
        "    # Determine filename using URL\n",
        "    parse = urllib.parse.urlparse(url)\n",
        "    file_name = os.path.basename(parse.path)\n",
        "    if file_name == '':\n",
        "        file_name = md5_hash(parse.path)\n",
        "\n",
        "    temp_file_name = file_name + \".part\"\n",
        "    full_name = os.path.join(data_dir, file_name)\n",
        "    temp_full_name = os.path.join(data_dir, temp_file_name)\n",
        "    if os.path.exists(full_name):\n",
        "        if overwrite:\n",
        "            os.remove(full_name)\n",
        "        else:\n",
        "            return full_name\n",
        "    if os.path.exists(temp_full_name):\n",
        "        if overwrite:\n",
        "            os.remove(temp_full_name)\n",
        "    t0 = time.time()\n",
        "    local_file = None\n",
        "    initial_size = 0\n",
        "\n",
        "    try:\n",
        "        # Download data\n",
        "        headers = {}\n",
        "        auth = None\n",
        "        if username is not None and password is not None:\n",
        "            if not url.startswith('https'):\n",
        "                raise ValueError(\n",
        "                    'Authentication was requested on a non  secured URL (%s).'\n",
        "                    'Request has been blocked for security reasons.' % url)\n",
        "            auth = (username, password)\n",
        "        if verbose > 0:\n",
        "            displayed_url = url.split('?')[0] if verbose == 1 else url\n",
        "            print('Downloading data from %s ...' % displayed_url)\n",
        "        if resume and os.path.exists(temp_full_name):\n",
        "            # Download has been interrupted, we try to resume it.\n",
        "            local_file_size = os.path.getsize(temp_full_name)\n",
        "            # If the file exists, then only download the remainder\n",
        "            headers[\"Range\"] = \"bytes={}-\".format(local_file_size)\n",
        "            try:\n",
        "                req = requests.Request(\n",
        "                    method=\"GET\", url=url, headers=headers, auth=auth)\n",
        "                prepped = session.prepare_request(req)\n",
        "                with session.send(prepped, stream=True,\n",
        "                                  timeout=_REQUESTS_TIMEOUT) as resp:\n",
        "                    resp.raise_for_status()\n",
        "                    content_range = resp.headers.get('Content-Range')\n",
        "                    if (content_range is None or not content_range.startswith(\n",
        "                            'bytes {}-'.format(local_file_size))):\n",
        "                        raise IOError('Server does not support resuming')\n",
        "                    initial_size = local_file_size\n",
        "                    with open(local_file, \"ab\") as fh:\n",
        "                        _chunk_read_(\n",
        "                            resp, fh, report_hook=(verbose > 0),\n",
        "                            initial_size=initial_size, verbose=verbose)\n",
        "            except Exception:\n",
        "                if verbose > 0:\n",
        "                    print('Resuming failed, try to download the whole file.')\n",
        "                return _fetch_file(\n",
        "                    url, data_dir, resume=False, overwrite=overwrite,\n",
        "                    md5sum=md5sum, username=username, password=password,\n",
        "                    verbose=verbose, session=session)\n",
        "        else:\n",
        "            req = requests.Request(\n",
        "                method=\"GET\", url=url, headers=headers, auth=auth)\n",
        "            prepped = session.prepare_request(req)\n",
        "            with session.send(\n",
        "                    prepped, stream=True, timeout=_REQUESTS_TIMEOUT) as resp:\n",
        "                resp.raise_for_status()\n",
        "                with open(temp_full_name, \"wb\") as fh:\n",
        "                    _chunk_read_(resp, fh, report_hook=(verbose > 0),\n",
        "                                 initial_size=initial_size, verbose=verbose)\n",
        "        shutil.move(temp_full_name, full_name)\n",
        "        dt = time.time() - t0\n",
        "        if verbose > 0:\n",
        "            # Complete the reporting hook\n",
        "            sys.stderr.write(' ...done. ({0:.0f} seconds, {1:.0f} min)\\n'\n",
        "                             .format(dt, dt // 60))\n",
        "    except (requests.RequestException):\n",
        "        sys.stderr.write(\"Error while fetching file %s; dataset \"\n",
        "                         \"fetching aborted.\" % (file_name))\n",
        "        raise\n",
        "    if md5sum is not None:\n",
        "        if (_md5_sum_file(full_name) != md5sum):\n",
        "            raise ValueError(\"File %s checksum verification has failed.\"\n",
        "                             \" Dataset fetching aborted.\" % local_file)\n",
        "    return full_name\n",
        "\n",
        "\n",
        "def _get_dataset_descr(ds_name):\n",
        "    module_path = os.path.dirname(os.path.abspath(__file__))\n",
        "\n",
        "    fname = ds_name\n",
        "\n",
        "    try:\n",
        "        with open(os.path.join(module_path, 'description', fname + '.rst'),\n",
        "                  'rb') as rst_file:\n",
        "            descr = rst_file.read()\n",
        "    except IOError:\n",
        "        descr = ''\n",
        "\n",
        "    if descr == '':\n",
        "        warnings.warn(\"Could not find dataset description.\")\n",
        "\n",
        "    if isinstance(descr, bytes):\n",
        "        descr = descr.decode('utf-8')\n",
        "\n",
        "    return descr\n",
        "\n",
        "\n",
        "def movetree(src, dst):\n",
        "    \"\"\"Move an entire tree to another directory. Any existing file is\n",
        "    overwritten\"\"\"\n",
        "    names = os.listdir(src)\n",
        "\n",
        "    # Create destination dir if it does not exist\n",
        "    if not os.path.exists(dst):\n",
        "        os.makedirs(dst)\n",
        "    errors = []\n",
        "\n",
        "    for name in names:\n",
        "        srcname = os.path.join(src, name)\n",
        "        dstname = os.path.join(dst, name)\n",
        "        try:\n",
        "            if os.path.isdir(srcname) and os.path.isdir(dstname):\n",
        "                movetree(srcname, dstname)\n",
        "                os.rmdir(srcname)\n",
        "            else:\n",
        "                shutil.move(srcname, dstname)\n",
        "        except (IOError, os.error) as why:\n",
        "            errors.append((srcname, dstname, str(why)))\n",
        "        # catch the Error from the recursive movetree so that we can\n",
        "        # continue with other files\n",
        "        except Exception as err:\n",
        "            errors.extend(err.args[0])\n",
        "    if errors:\n",
        "        raise Exception(errors)\n",
        "\n",
        "\n",
        "\n",
        "def _fetch_files(data_dir, files, resume=True, verbose=1, session=None):\n",
        "    \"\"\"Load requested dataset, downloading it if needed or requested.\n",
        "\n",
        "    This function retrieves files from the hard drive or download them from\n",
        "    the given urls. Note to developers: All the files will be first\n",
        "    downloaded in a sandbox and, if everything goes well, they will be moved\n",
        "    into the folder of the dataset. This prevents corrupting previously\n",
        "    downloaded data. In case of a big dataset, do not hesitate to make several\n",
        "    calls if needed.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    %(data_dir)s\n",
        "    files : list of (string, string, dict)\n",
        "        List of files and their corresponding url with dictionary that contains\n",
        "        options regarding the files. Eg. (file_path, url, opt). If a file_path\n",
        "        is not found in data_dir, as in data_dir/file_path the download will\n",
        "        be immediately cancelled and any downloaded files will be deleted.\n",
        "        Options supported are:\n",
        "            * 'move' if renaming the file or moving it to a subfolder is needed\n",
        "            * 'uncompress' to indicate that the file is an archive\n",
        "            * 'md5sum' to check the md5 sum of the file\n",
        "            * 'overwrite' if the file should be re-downloaded even if it exists\n",
        "    %(resume)s\n",
        "    %(verbose)s\n",
        "    session : `requests.Session`, optional\n",
        "        Session to use to send requests.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    files : list of string\n",
        "        Absolute paths of downloaded files on disk.\n",
        "\n",
        "    \"\"\"\n",
        "    if session is None:\n",
        "        with requests.Session() as session:\n",
        "            session.mount(\"ftp:\", _NaiveFTPAdapter())\n",
        "            return _fetch_files(\n",
        "                data_dir, files, resume=resume,\n",
        "                verbose=verbose, session=session)\n",
        "    # There are two working directories here:\n",
        "    # - data_dir is the destination directory of the dataset\n",
        "    # - temp_dir is a temporary directory dedicated to this fetching call. All\n",
        "    #   files that must be downloaded will be in this directory. If a corrupted\n",
        "    #   file is found, or a file is missing, this working directory will be\n",
        "    #   deleted.\n",
        "    files = list(files)\n",
        "    files_pickle = pickle.dumps([(file_, url) for file_, url, _ in files])\n",
        "    files_md5 = hashlib.md5(files_pickle).hexdigest()\n",
        "    temp_dir = os.path.join(data_dir, files_md5)\n",
        "\n",
        "    # Create destination dir\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "\n",
        "    # Abortion flag, in case of error\n",
        "    abort = None\n",
        "\n",
        "    files_ = []\n",
        "    for file_, url, opts in files:\n",
        "        # 3 possibilities:\n",
        "        # - the file exists in data_dir, nothing to do.\n",
        "        # - the file does not exists: we download it in temp_dir\n",
        "        # - the file exists in temp_dir: this can happen if an archive has been\n",
        "        #   downloaded. There is nothing to do\n",
        "\n",
        "        # Target file in the data_dir\n",
        "        target_file = os.path.join(data_dir, file_)\n",
        "        # Target file in temp dir\n",
        "        temp_target_file = os.path.join(temp_dir, file_)\n",
        "        # Whether to keep existing files\n",
        "        overwrite = opts.get('overwrite', False)\n",
        "        if (abort is None and (overwrite or (not os.path.exists(target_file) and not\n",
        "                os.path.exists(temp_target_file)))):\n",
        "\n",
        "            # We may be in a global read-only repository. If so, we cannot\n",
        "            # download files.\n",
        "            if not os.access(data_dir, os.W_OK):\n",
        "                raise ValueError('Dataset files are missing but dataset'\n",
        "                                 ' repository is read-only. Contact your data'\n",
        "                                 ' administrator to solve the problem')\n",
        "\n",
        "            if not os.path.exists(temp_dir):\n",
        "                os.mkdir(temp_dir)\n",
        "            md5sum = opts.get('md5sum', None)\n",
        "\n",
        "            dl_file = _fetch_file(url, temp_dir, resume=resume,\n",
        "                                  verbose=verbose, md5sum=md5sum,\n",
        "                                  username=opts.get('username', None),\n",
        "                                  password=opts.get('password', None),\n",
        "                                  session=session, overwrite=overwrite)\n",
        "            if 'move' in opts:\n",
        "                # XXX: here, move is supposed to be a dir, it can be a name\n",
        "                move = os.path.join(temp_dir, opts['move'])\n",
        "                move_dir = os.path.dirname(move)\n",
        "                if not os.path.exists(move_dir):\n",
        "                    os.makedirs(move_dir)\n",
        "                shutil.move(dl_file, move)\n",
        "                dl_file = move\n",
        "            if 'uncompress' in opts:\n",
        "                try:\n",
        "                    _uncompress_file(dl_file, verbose=verbose)\n",
        "                except Exception as e:\n",
        "                    abort = str(e)\n",
        "\n",
        "        if (abort is None and not os.path.exists(target_file) and not\n",
        "                os.path.exists(temp_target_file)):\n",
        "            warnings.warn('An error occurred while fetching %s' % file_)\n",
        "            abort = (\"Dataset has been downloaded but requested file was \"\n",
        "                     \"not provided:\\nURL: %s\\n\"\n",
        "                     \"Target file: %s\\nDownloaded: %s\" %\n",
        "                     (url, target_file, dl_file))\n",
        "        if abort is not None:\n",
        "            if os.path.exists(temp_dir):\n",
        "                shutil.rmtree(temp_dir)\n",
        "            raise IOError('Fetching aborted: ' + abort)\n",
        "        files_.append(target_file)\n",
        "    # If needed, move files from temps directory to final directory.\n",
        "    if os.path.exists(temp_dir):\n",
        "        # XXX We could only moved the files requested\n",
        "        # XXX Movetree can go wrong\n",
        "        movetree(temp_dir, data_dir)\n",
        "        shutil.rmtree(temp_dir)\n",
        "    return files_\n",
        "\n",
        "\n",
        "def _tree(path, pattern=None, dictionary=False):\n",
        "    \"\"\"Return a directory tree under the form of a dictionaries and list\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    path : string\n",
        "        Path browsed.\n",
        "\n",
        "    pattern : string, optional\n",
        "        Pattern used to filter files (see fnmatch).\n",
        "\n",
        "    dictionary : boolean, optional\n",
        "        If True, the function will return a dict instead of a list.\n",
        "        Default=False.\n",
        "\n",
        "    \"\"\"\n",
        "    files = []\n",
        "    dirs = [] if not dictionary else {}\n",
        "    for file_ in os.listdir(path):\n",
        "        file_path = os.path.join(path, file_)\n",
        "        if os.path.isdir(file_path):\n",
        "            if not dictionary:\n",
        "                dirs.append((file_, _tree(file_path, pattern)))\n",
        "            else:\n",
        "                dirs[file_] = _tree(file_path, pattern)\n",
        "        else:\n",
        "            if pattern is None or fnmatch.fnmatch(file_, pattern):\n",
        "                files.append(file_path)\n",
        "    files = sorted(files)\n",
        "    if not dictionary:\n",
        "        return sorted(dirs) + files\n",
        "    if len(dirs) == 0:\n",
        "        return files\n",
        "    if len(files) > 0:\n",
        "        dirs['.'] = files\n",
        "    return dirs\n",
        "\n",
        "\n",
        "\n",
        "def make_fresh_openneuro_dataset_urls_index(\n",
        "        data_dir=None,\n",
        "        dataset_version='ds000030_R1.0.4',\n",
        "        verbose=1,\n",
        "        ):\n",
        "    \"\"\"ONLY intended for Nilearn developers, not general users.\n",
        "    Creates a fresh, updated OpenNeuro :term:`BIDS` dataset index from AWS,\n",
        "    ready for upload to osf.io .\n",
        "\n",
        "    Crawls the server where OpenNeuro dataset is stored\n",
        "    and makes a JSON file `nistats_fetcher_openneuro_dataset_urls.json'\n",
        "    containing a fresh list of dataset file URLs.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    Needs Python package `Boto3`.\n",
        "\n",
        "    Do NOT rename this file.\n",
        "\n",
        "    This file can now be uploaded to Quick-Files section\n",
        "    of the Nilearn account on osf.io .\n",
        "\n",
        "    Then this file can be downloaded by\n",
        "    :func:`datasets.fetch_openneuro_dataset_index`\n",
        "\n",
        "    Run this function and upload the new file if the URL index downloaded by\n",
        "    :func:`datasets.fetch_openneuro_dataset_index` becomes outdated.\n",
        "\n",
        "    This approach is faster than crawling the servers anew every time\n",
        "    the OpenNeuro dataset is downloaded,\n",
        "    and circumvents `boto3` as a dependency for everyday use.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    %(data_dir)s\n",
        "    dataset_version : string, optional\n",
        "        Dataset version name. Assumes it is of the form [name]_[version].\n",
        "        Default is `ds000030_R1.0.4`.\n",
        "    %(verbose)s\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    urls_path : string\n",
        "        Path to downloaded dataset index.\n",
        "\n",
        "    urls : list of string\n",
        "        Sorted list of dataset directories.\n",
        "\n",
        "    \"\"\"\n",
        "    import boto3\n",
        "    from botocore.handlers import disable_signing\n",
        "    if not data_dir:\n",
        "        data_dir = os.path.expanduser('~/Desktop')\n",
        "    data_prefix = '{}/{}/uncompressed'.format(\n",
        "        dataset_version.split('_')[0], dataset_version)\n",
        "\n",
        "    data_dir = _get_dataset_dir(data_prefix, data_dir=data_dir,\n",
        "                                verbose=verbose)\n",
        "\n",
        "    # First we download the url list from the uncompressed dataset version\n",
        "    urls_path = os.path.join(data_dir,\n",
        "                             'nistats_fetcher_openneuro_dataset_urls.json',\n",
        "                             )\n",
        "    urls = []\n",
        "    if os.path.exists(urls_path):\n",
        "        with open(urls_path, 'r') as json_file:\n",
        "            urls = json.load(json_file)\n",
        "        existing_index_msg = (\"There is an existing url index at `{}`. \"\n",
        "                              \"Aborting download of fresh index.\"\n",
        "                              .format(urls_path)\n",
        "                              )\n",
        "        print(existing_index_msg)\n",
        "    else:\n",
        "        resource = boto3.resource('s3')\n",
        "        resource.meta.client.meta.events.register('choose-signer.s3.*',\n",
        "                                                  disable_signing)\n",
        "        bucket = resource.Bucket('openneuro')\n",
        "\n",
        "        for obj in bucket.objects.filter(Prefix=data_prefix):\n",
        "            # get url of files (keys of directories end with '/')\n",
        "            if obj.key[-1] != '/':\n",
        "                url = '{}/{}/{}'.format(bucket.meta.client.meta.endpoint_url,\n",
        "                                        bucket.name,\n",
        "                                        obj.key,\n",
        "                                        )\n",
        "                urls.append(url)\n",
        "        urls = sorted(urls)\n",
        "\n",
        "        with open(urls_path, 'w') as json_file:\n",
        "            json.dump(urls, json_file)\n",
        "        print(\"Saved updated url index to {}.\\nUpload it with the same name \"\n",
        "              \"to the quick-files section of osf.io using the Nilearn account \"\n",
        "              \"to update the file without breaking the fetcher download link.\"\n",
        "              .format(urls_path))\n",
        "    return urls_path, urls\n"
      ],
      "metadata": {
        "id": "r_GDQbtg0Icf"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve4uDJxvhf4q"
      },
      "source": [
        "### Visualisation avec T-SNE\n",
        "\n",
        "Les embeddings sont des vecteurs de plusieurs centaines de dimensions. Il n'est donc pas possible de les visualiser dans leur espace d'origine. Il est par contre possible d'appliquer des algorithmes de réduction de dimension pour les visualiser en 2 ou 3 dimension. Un des algorithmes de réduction de dimension permettant une visualisation en 2D est [tSNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding).\n",
        "\n",
        "#### Question\n",
        "> * créer un object `word_vectors` de type `np.array` à partir d'une liste contenant tous les embeddings des mots de la liste `words_plus_neighbors`\n",
        "> * créer un objet tSNE à partir de la librairie `from sklearn.manifold import TSNE` avec les paramètres `random_state=0`, `n_iter=2000` et `perplexity=15.0` pour une visualisation en 2 dimensions\n",
        "> * Calculer *T* la transformation tSNE des vecteur `word_vectors` en appliquant la function `.fit_transform(word_vectors)` à l'objet tSNE. Cette fonction estime les paramètres de la transformation tSNE et retourne la représentation en dimension réduite des vecteurs utilisés pour l'estimation.\n",
        "> * Utiliser la fonction `scatterplot` de [seaborn](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) pour représenter les points en 2 dimensions  et ajouter les labels des mots avec la function `plt.annotate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "1BN7uIirhf4r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a465131-821e-4dfb-9048-ef8214c4a4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.70788   -0.209046  -0.108115   1.04061   -0.149587  -0.505998\n",
            "   1.449     -0.508682  -0.278779  -0.0409594 -1.32884   -0.374204\n",
            "  -0.216364  -0.979481  -0.227005   1.01935    1.8784     0.0566259\n",
            "  -0.346927  -0.962002  -0.262201   0.102108   0.731819   0.410081\n",
            "  -1.22421   -1.26328   -0.944767  -1.12969    1.05038    1.31144\n",
            "  -0.789239  -0.0730487 -0.514356   1.04031    0.544979   0.784452\n",
            "  -1.44307   -0.456403  -1.49253   -1.58255   -2.93436    0.645818\n",
            "  -0.194853   0.668236  -0.335912  -0.0174363 -1.56638   -0.0311665\n",
            "   1.19117    1.69714  ]\n",
            " [-0.0664335 -0.169104  -0.107782  -1.16959    1.70738    0.697106\n",
            "  -0.819087   0.266313  -1.08463   -0.619686   0.338519  -1.34517\n",
            "   0.758125   0.171826  -0.86451    0.948554   1.14141   -1.40546\n",
            "   0.472006   1.3859     0.179484   0.345274  -0.525065   0.813772\n",
            "  -0.386274  -0.44053    0.821619   1.13767   -0.645065  -0.608829\n",
            "   0.993586  -0.0754916 -0.934398   1.96718    0.705519   0.472874\n",
            "  -3.16359   -0.738756   0.247753   1.09656   -1.50026   -1.02104\n",
            "  -0.60975   -1.02076   -0.216731   0.629631  -0.977576  -0.590819\n",
            "  -1.2663    -0.0349852]\n",
            " [-0.390565   0.507571  -0.218421  -1.44518   -0.140737   0.0855533\n",
            "  -1.0723     1.7425    -0.536528  -0.78173   -1.44176   -0.184942\n",
            "   0.775947  -1.5113    -1.2873     1.3337     0.856875   0.661733\n",
            "  -0.283661  -0.513386  -0.313803   0.329493  -0.177292   0.96786\n",
            "  -1.18107   -1.49078    0.254848  -0.031469   0.107964   2.58456\n",
            "  -0.884342   0.109821   1.63731    0.61717   -0.290083   0.279274\n",
            "  -1.34068    1.07469   -0.300524  -0.419325  -0.589735   0.926951\n",
            "   0.870045   0.608993  -1.61876    0.293302   0.132686   0.143462\n",
            "  -0.302551   0.606359 ]\n",
            " [ 0.100362   0.751582   2.46517    0.211352   1.24578   -1.35283\n",
            "  -0.0921332  0.464966  -0.485856   0.893575  -0.339342   0.898479\n",
            "   1.22232   -0.505012   0.634676   0.501736  -0.78868   -0.38804\n",
            "  -0.210837  -0.703638  -2.03753    0.276822   0.38959   -0.372674\n",
            "  -0.105841  -1.03306    0.0929984  1.87132    1.30235    0.87464\n",
            "   1.10385   -0.976547  -2.39573    0.934723  -0.369476   0.309513\n",
            "   0.729115  -0.562544  -1.44944    0.229462  -0.444939   1.97196\n",
            "  -1.33455   -0.199735  -0.18041   -1.07582   -1.07976   -0.180172\n",
            "  -0.816252  -0.125633 ]\n",
            " [-2.63944    0.170319   1.06319   -1.37865    0.571561  -0.773152\n",
            "   0.482808   0.346711  -1.8387    -0.34097   -1.85733   -0.474207\n",
            "   0.39637   -0.594685  -0.132451   2.01531    0.0126529  1.57577\n",
            "   0.0114396 -0.483729  -0.900382  -0.339645   1.58751   -0.401757\n",
            "   0.0978991  0.246586  -1.64098   -0.442377   0.769785   1.32194\n",
            "   0.243158  -0.121304   0.412233   1.07295   -0.426718   1.34319\n",
            "  -0.683724  -0.67526   -0.495318   0.835709  -1.27115    1.33984\n",
            "  -0.133666   0.621727   1.12162   -1.18623    0.7649     0.373714\n",
            "   0.456811   1.24424  ]\n",
            " [-3.12214   -1.02558    0.870508  -1.2914     0.643111  -0.751171\n",
            "   0.217318   1.24014   -0.74286   -0.964147  -1.36485   -0.827964\n",
            "   0.0788627 -1.22419   -0.467986   2.57128    0.358653   0.695055\n",
            "   0.0874599  0.114838  -0.180332  -0.384416   0.630696   0.613675\n",
            "  -0.220088  -0.489548  -0.407919  -0.0510641  1.9257     0.632734\n",
            "  -1.18227   -0.208445   0.509013   0.643182   0.736428   1.38459\n",
            "  -0.950764   0.626965  -1.7126     0.737402   0.513274   0.660243\n",
            "   0.647101   0.0773243  0.987193  -1.34035    0.400834   0.535921\n",
            "  -0.475022   0.60341  ]\n",
            " [-0.0473019  0.766563  -0.984998  -0.0515589 -0.265532   0.134051\n",
            "   0.141417   1.01374   -0.619591  -1.03638   -2.42887    0.211645\n",
            "   1.22525   -0.851744  -0.58964    1.32913    1.34745    1.11541\n",
            "   1.05763   -1.06567   -0.0968101 -0.0134965 -0.026164   0.874596\n",
            "   0.0476788 -0.911441  -0.613813   0.180014   1.37738    1.40552\n",
            "  -1.08816   -0.515869   0.90306    1.47399    0.263308   0.969817\n",
            "  -2.54524    0.450224  -0.0949713 -0.477236  -1.29267    0.273579\n",
            "   0.797852  -0.0928017 -1.52663   -0.491025  -0.413876  -0.928283\n",
            "  -0.918091   0.878262 ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2kAAALGCAYAAADftdkpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABw0UlEQVR4nO3dd3QU9f7/8deWhBRICBBCLwkmgJSEXgIqIr0oFwS9oFgQpF1QLgJyvV71XhX1K1WpooAgSBcREZVeBEURQVpAmoSSkB6SbOb3B7+srgkQQiCT7PNxDgd25jMz7913NuSV+cysxTAMQwAAAAAAU7AWdAEAAAAAgD8Q0gAAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQBAAAAgIkQ0gAUCcuXL1dYWJhOnz5tujr69eunfv363fFaCuq47sAsX28FadeuXQoLC9OuXbsKuhQAKHLsBV0AAORk0KBB2rFjh7Zt26bixYvnOOb555/Xl19+qS1bttzh6szj6NGj+uKLL/TQQw+pUqVKBV2OpLzVlJaWpkWLFmnFihU6efKkrFargoKC1KBBA/Xv318hISGSroajsWPHytPTUxs2bFBQUJDLfvr166fY2FitWbPGuaxNmzY6c+ZMjseNjIzUnDlz8vhMURikpKRo9uzZatKkiZo2bVrQ5dxxO3bs0OrVq/XDDz/o3LlzKlOmjJo1a6Z//OMfKlu2rMvYP79XLBaLihcvrvLlyys8PFw9e/ZU/fr1C+IpAG6JkAbAlLp166Zvv/1WGzZs0IMPPphtfUpKir755htFRkYqICBA3bt3V+fOneXp6Xnni72B2xkCjh49qqlTp6pJkybZAlFBhY/r1XQtw4cP1+bNm9W5c2f16tVLGRkZioqK0saNGxUREeEMaVnS0tI0c+ZM/etf/8rV/mvVqqUnnngi2/K//pCKoiclJUVTp07V0KFD3TKkvfXWW4qLi1OHDh1UrVo1nTp1SgsWLNDGjRu1cuVKBQYGuoz/83slKSlJUVFRWrdunZYsWaL+/ftr7NixBfE0ALdDSANgSm3atJGvr68+++yzHEPa119/reTkZHXr1k2SZLPZZLPZ7nCVuVNQwdGMgTUn+/bt07fffquRI0dq0KBBLuscDofi4+OzbVOrVi0tWbJEzzzzTLazaTkJCgpS9+7d861md2AYhq5cuSIvL6+CLsWUkpOT5ePjU9Bl3NDYsWPVsGFDWa1/XOHSqlUr9e3bVwsWLNDIkSNdxuf0Xhk1apSef/55ffjhh6pataoeffTRO1I74M64Jg2AKXl5ealdu3bauXOnLl26lG39mjVr5OvrqzZt2kjK+Rqhn3/+WU899ZSaNm2qevXqqU2bNi6/Bb7WNTWnT59WWFiYli9f7lz266+/asyYMbr//vtVt25dtWzZUmPHjlVsbOwNn0tO14bNnz9fnTt3Vv369dW4cWP16NFDn332mXP9mTNn9PLLL6t9+/aqV6+emjZtquHDh7s8v+XLl+sf//iHJOmxxx5TWFiYy/PJ6biXLl3SuHHj1KJFC9WtW1fdunXTihUrcnz+c+bM0eLFi9W2bVvVqVNHf/vb37Rv377rPtcb1ZSTU6dOSZIaNGiQbZ3NZlNAQEC25QMHDlRmZqZmzZp13Xryw5EjR/TYY4+pXr16at26td577z1lZmbmOHbTpk169NFHFR4eroiICD3zzDM6cuSIy5gLFy5o7Nixat26terUqaPIyEg9++yz172+7euvv1ZYWJh+/fVX57Ivv/xSYWFhGjp0qMvYjh07asSIEc7HGRkZmjZtmrOPbdq00f/93/8pLS3NZbs2bdpo4MCB2rJli3r06KF69erpk08+kSSdO3dOgwcPVnh4uJo3b67//e9/2ba/kZ9//llhYWHZvt4kacuWLQoLC9O3337rXBYdHa2xY8eqRYsWqlOnjjp37qylS5dm2/bKlSuaMmWK2rdvr7p16yoyMlJDhw7VyZMndfr0aTVv3lySNHXqVOfX45QpU5zb79ixw9mzRo0a6dlnn9WxY8dcjjFlyhSFhYXp6NGjev7559W4cWNnUMlLP7McO3ZMw4cPV5MmTVS3bl316NFDX3/9tcuYrO9t33//vV5//XU1a9ZM4eHhGjJkiGJiYm54jMaNG7sEtKxlJUuWVFRU1A23l65+P54wYYJKliyp6dOnyzCMXG0HIO84kwbAtLp27aoVK1boiy++UN++fZ3LL1++rK1bt6pz587X/C3/pUuX9NRTTykgIEDPPPOM/Pz8dPr0aX311Vd5qmX79u06deqUevToocDAQB05ckRLlizR0aNHtWTJElksllzva8mSJXrttdfUvn17PfbYY7py5YoOHTqkn376SV27dpV09QfavXv3qnPnzipXrpzOnDmjRYsW6bHHHtPnn38ub29vNW7cWP369dP8+fM1aNAgBQcHS1K2qYFZUlNT1a9fP508eVJ///vfValSJa1bt05jxoxRfHy8Hn/8cZfxa9asUVJSknr37i2LxaLZs2dr2LBh2rBhgzw8PHI8xs3WJEkVKlSQJH322Wdq0KCB7PYb/9dUqVIlde/eXUuWLNGAAQNueDYtIyMjxx9ofXx8rnum6MKFC3rsscfkcDj0zDPPyNvbW0uWLFGxYsWyjV25cqXGjBmjyMhIjRo1SikpKVq0aJEeffRRrVixwjn1c9iwYTp69Kj69u2rihUrKiYmRtu2bdPvv/9+zemhDRs2lMVi0Z49e1SzZk1J0p49e2S1WvX99987x8XExCgqKsrl/TJ+/HitWLFC7du31xNPPKF9+/ZpxowZOnbsmKZNm+ZynOPHj+v5559X79699fDDD6t69epKTU3V448/rt9//139+vVT2bJltWrVKu3cufM6r3h2devWVeXKlZ3XK/7Z2rVr5e/vr8jISEnSxYsX9fDDD8tisejvf/+7SpUqpc2bN+vFF19UYmKi+vfvL+nqmdaBAwdqx44d6ty5sx577DElJSVp27ZtOnz4sFq0aKGXX35ZL7/8sh544AE98MADkqSwsDBJV9/XAwYMUKVKlTR06FClpqZqwYIFeuSRR7R8+fJs/fjHP/6hqlWrauTIkc6gkpd+SlfD/yOPPKKgoCANGDBAPj4++uKLLzRkyBBNmTLFWWuW1157TX5+fho6dKjOnDmjjz76SK+88oomTpx4U32Qrk5jTEpKyvEXINfi6+urtm3baunSpTp69Kjuuuuumz4ugJtgAIBJZWRkGC1btjR69+7tsnzRokVGaGiosWXLFueyZcuWGaGhocapU6cMwzCMr776yggNDTX27dt3zf3v3LnTCA0NNXbu3Omy/NSpU0ZoaKixbNky57KUlJRs269Zs8YIDQ01du/efc06DMMw+vbta/Tt29f5+NlnnzU6d+583eee0/H27t1rhIaGGitWrHAu++KLL3J8Djkd98MPPzRCQ0ONVatWOZelpaUZvXv3NsLDw42EhASX59+kSRPj8uXLzrEbNmwwQkNDjW+++ea6tV+vppxkZmYaffv2NUJDQ40WLVoYzz33nLFgwQLjzJkz2cZmvb779u0zTp48adSuXdt49dVXXZ7zX1/b++67zwgNDc3xz4wZM65b23//+18jNDTU+Omnn5zLLl26ZDRs2NClz4mJiUajRo2M8ePHu2x/4cIFo2HDhs7lcXFxRmhoqDF79uxcvTZ/1rlzZ+Mf//iH8/FDDz1kDB8+3AgNDTWOHj1qGIZhrF+/3ggNDTUOHjxoGIZhHDx40AgNDTVefPFFl3298cYbRmhoqLFjxw7nsqzXafPmzS5js75u1q5d61yWnJxsPPDAAzfVZ8MwjHfeece4++67Xb6urly5YjRq1MgYO3asc9m4ceOMli1bGjExMS7bjxw50mjYsKHz/bF06VIjNDTUmDt3brZjZWZmGoZxtV+hoaHG5MmTs43p3r270bx5cyM2Nta57ODBg0bNmjWN0aNHO5dNnjzZCA0NNZ577jmX7W+ln48//rjRpUsX48qVKy419+7d22jXrp1zWdbXfP/+/Z3PyTAM43//+59Rq1YtIz4+/qaPPW3aNCM0NNTYvn27y/L77rvPeOaZZ6653dy5c43Q0FBjw4YNN31MADeH6Y4ATMtms6lz587au3evy9ShNWvWqEyZMs5pTDkpUaKEJGnjxo1KT0+/5Vr+fLblypUriomJcd7p7Jdffrmpffn5+encuXPXnTr45+Olp6crNjZWVapUkZ+fnw4cOHCT1V+1efNmBQYGqkuXLs5lHh4e6tevn5KTk7V7926X8Z06dZK/v7/zcaNGjST9MT0xv1gsFs2ZM0cjRoyQn5+f1qxZo1deeUX33XefRowYkeM1aZJUuXJldevWTUuWLNH58+eve4z69etr7ty52f507tz5uttt2rRJ4eHhqlevnnNZqVKlnGc8s2zfvl3x8fHq3LmzYmJinH+sVqvq16/vnO7p5eUlDw8Pfffdd4qLi8vNy+PUsGFD7dmzR5KUmJioX3/9Vb1791ZAQIDzbNqePXvk5+en0NBQZ/2Sst005cknn3RZn6VSpUpq1aqVy7Ksr5sOHTo4l3l7e+vhhx++qfqlq19T6enpWr9+vXPZtm3bFB8fr06dOkm6ei3c+vXr1aZNGxmG4fJ6RkZGKiEhwfmeW79+vQICAlzOHGa50dnt8+fP6+DBg3rooYdUsmRJ5/KaNWuqRYsW2V4bSerTp4/L47z28/Lly9q5c6c6duyoxMRE5/OLjY1VZGSkTpw4oejoaJdtss4sZmnUqJEcDsc171x6Lbt379a0adPUsWPH634PzYmvr6+kq2fiANxeTHcEYGpdu3bVhx9+qDVr1mjQoEE6d+6c9uzZo379+l33RiFNmjRR+/btNXXqVH344Ydq0qSJ2rZtq65du+bphhqXL1/W1KlTtXbt2mzXyCUkJNzUvgYMGKDt27erV69eqlq1qlq2bKkuXbqoYcOGzjGpqamaMWOGli9frujoaJdrQG72eFnOnDmjqlWrZrs+JWsq4tmzZ12Wly9f3uVxVmC7Vmi6kYSEBKWmpjofe3h4OH849vT01LPPPqtnn31W58+f1+7duzVv3jx98cUXstvtevvtt3Pc5+DBg7V69WrNnDlT48ePv+axAwIC1KJFi5uu+ezZsznedrx69eouj0+cOCFJ2aaMZsn6GAlPT0+NGjVKb775plq2bKn69evr3nvv1YMPPpjtLnt/1ahRI33yySf67bffdPLkSVksFud1VHv27NHDDz+sPXv2qEGDBs4enzlzRlarVVWqVHHZV2BgoPz8/LL9gJ/T9Lysr5u/hp6/vga5UbNmTQUHB+uLL75Qr169JF2d6hgQEKBmzZpJujplMz4+XosXL9bixYtz3E/W1NWTJ0+qevXquZoi+1dZX+85PY+QkBBt3bo1281B/vr65LWfJ0+elGEYmjRpkiZNmpTjmEuXLrlM482aFpzFz89P0s29H48dO6ahQ4fqrrvu0muvvZbr7bJkhbOssAbg9iGkATC1OnXqKDg4WJ9//rkGDRqkNWvWyDCMbGcy/spisWjy5Mn68ccf9e2332rLli0aN26c5s6dq8WLF8vX1/eav2nP6aYQI0aM0N69e/XUU0+pVq1a8vHxUWZmpp5++umbvog+JCRE69at08aNG7VlyxatX79eCxcu1JAhQzR8+HBJ0quvvqrly5fr8ccfV3h4uEqUKCGLxeJyLcztdq0QnNfj//e//3W5aUSTJk00f/78bOPKli2rzp07q127durSpYvWrVunN954I8cfxP98Nu2ZZ57JU135Ies1mTBhQo4/nP/5tezfv7/atGmjDRs2aOvWrZo0aZJmzpypjz76SLVr177mMbJC/O7du3Xq1CnVrl1bPj4+atSokebNm6ekpCQdPHjQ5aYhWXJ7zeSduJNjp06dNH36dMXExKh48eL65ptv1LlzZ2d/s95/3bp1y3btWpasa8rutJyuRcxLP7Oe45NPPpntzGWWvwbrv/5yJUtu34+///67nnrqKRUvXlwzZ8685udPXk/WTXCqVq1609sCuDmENACm17VrV02aNEm//vqr1qxZo2rVqrlMP7ue8PBwhYeHa+TIkfrss880atQorV27Vr169XL+JvqvZ6b+enYhLi5OO3bs0LBhw1zupJd19iQvfHx81KlTJ3Xq1ElpaWkaNmyYpk+froEDB6pYsWL68ssv9eCDD2rMmDHOba5cuZKt1pu5YUnFihV16NAhZWZmuvzAl3WHt7/+pj6vrlXT008/7fzIBOmPMwHX4uHhobCwMJ04cUKxsbHXPDPx7LPPavXq1bflTo8VKlTQb7/9lm358ePHXR5XrlxZklS6dOlcnbGrUqWKnnzyST355JM6ceKEHnzwQX3wwQfXPGOYVUuFChX0/fff69SpU87pp40aNdLrr7+udevWyeFwqHHjxs5tKlasqMzMTP32228uN2+5ePGi4uPjVbFixRvWWrFiRR0+fFiGYbj09q+vQW516tRJU6dO1fr161WmTBklJia6TDstVaqUfH19lZmZecPXskqVKvrpp5+Unp5+zZvZXOvrMevrPafnERUVpYCAgFzfYv9m+5n19eLh4ZGnM7w3KzY2Vk8++aTS0tK0cOHCPH0+YFJSkjZs2KDy5ctf90ZAAPIH16QBML2ss2aTJ0/WwYMHb3gWTboarP76G+ZatWpJkvPW4RUrVpTNZst2LdaiRYtcHl/rjNJHH32UuyfwF3+9bb+np6dCQkJkGIbz+rmcjjl//nw5HA6XZd7e3pJyNwWydevWunDhgtauXetclpGRofnz58vHx8flh/tbca2aatSooRYtWjj/1KlTR9LVsPvXqZbS1Wlce/fulb+/v0qVKnXN41WpUkXdunXT4sWLdeHChXx5Dlnuuece/fjjjy7XD8bExLh8XIJ09XOnihcvrhkzZuR4DWTW9LyUlBRduXIlW/2+vr65uqV9w4YNtXPnTu3bt895Zq1WrVry9fXVzJkz5eXlpbvvvtulfin71+rcuXNd1l9P69atdf78ea1bt865LCUlRUuWLLnhtjkJCQlRaGio1q5dq7Vr1yowMNDla89ms6l9+/b68ssvdfjw4Wzb//kune3atVNsbKw+/vjjbOOy3v9ZX49/nRZYtmxZ1apVSytXrnRZd/jwYW3bti1Xr01e+1m6dGk1adJEixcvzvF6ytzcWj+3kpOT9cwzzyg6OlozZ85UtWrVbnofqampGj16tC5fvqxBgwbd1C+HAOQNZ9IAmF7lypUVERHh/Pyg3IS0FStWaNGiRWrbtq2qVKmipKQkLVmyRMWLF1fr1q0lXb25SIcOHbRgwQJZLBZVrlxZGzduzHbNWfHixdW4cWPNnj1b6enpCgoK0rZt23L1OUg5eeqpp1SmTBk1aNBApUuXVlRUlBYsWKB77rnHOQXp3nvv1apVq1S8eHHVqFFDP/74o7Zv3+5ygwPp6g/oNptNs2bNUkJCgjw9PdWsWTOVLl0623F79+6txYsXa8yYMfrll19UsWJFffnll/rhhx80bty4PE1/ysnN1CRd/Qy6UaNGqVWrVmrUqJH8/f0VHR2tlStX6vz58xo3btwNP6h80KBBWrVqlY4fP57jrcGjo6O1atWqbMuzbit+LU8//bRWrVqlp59+Wo899pjzFvwVKlTQoUOHnOOKFy+ul19+WaNHj1aPHj3UqVMnlSpVSmfPntWmTZvUoEEDvfTSSzpx4oT69++vDh06qEaNGrLZbNqwYYMuXrx4w5uYSFfPmn322WeyWCzOkGaz2RQREaGtW7eqSZMmLtdc1qxZUw899JAWL16s+Ph4NW7cWD///LNWrFihtm3bOq8Du56HH35YH3/8sV544QX98ssvCgwM1KpVq25pamSnTp00efJkFStWTD179sw2le/555/Xrl279PDDD6tXr16qUaOG4uLi9Msvv2jHjh367rvvJEkPPvigVq5cqddff90ZXFNSUrRjxw498sgjatu2rby8vFSjRg198cUXqlatmkqWLKm77rpLoaGhGj16tAYMGKDevXurZ8+ezlvwlyhRItvnz+XkVvr573//W48++qi6du2qhx9+WJUrV9bFixf1448/6ty5c1q9enWeX98/GzVqlPbt26e//e1vOnbsmMtnwOX09f/n90pycrKOHTumdevW6cKFC3ryySez3TwFwO1BSANQKHTt2lV79+5VvXr1cnU9RJMmTfTzzz9r7dq1unjxokqUKKF69erp7bffdk41kq5+hlRGRoY++eQTeXp6qkOHDho9erTLHRAl6Z133tGrr76qhQsXyjAMtWzZUrNmzbrm9STX07t3b3322WeaO3eukpOTVa5cOfXr10+DBw92jnnxxRdltVr12Wef6cqVK2rQoIHmzp2rp59+2mVfgYGB+s9//qMZM2boxRdflMPh0Lx583IMRF5eXpo/f77efvttrVixQomJiapevbpef/119ejR46afx7XcTE3S1c9WGz58uLZs2aK5c+cqNjZWvr6+qlWrlkaNGqX27dvf8JhVq1bN8YO5sxw8eFCjR4/OtrxixYrXDWlly5bVvHnz9Nprr2nmzJkqWbKk+vTpo7Jly+rFF190Gdu1a1eVLVtWM2fO1Jw5c5SWlqagoCA1atTI+fqWK1dOnTt31o4dO7R69WrZbDYFBwdr4sSJuXqeWVMcg4ODXT7jqlGjRtq6datz/Z+99tprqlSpklasWKENGzaoTJkyGjhwYK5CiHT1TNSHH36oV199VQsWLJCXl5e6du2q1q1bZ/t6zK1OnTpp4sSJSklJUceOHbOtL1OmjD799FNNmzZNX331lRYtWqSSJUuqRo0aGjVqlHNc1i8D3n//fa1Zs0br169XyZIl1aBBA5fr1l577TW9+uqrev3115Wenq6hQ4cqNDRULVq00OzZszV58mRNnjxZdrtdjRs31j//+U+X7xPXciv9rFGjhpYtW6apU6dqxYoVunz5skqVKqXatWtryJAhN/FqXl/WB6AvW7ZMy5Ytc1mX09d/1nvFYrHI19dX5cuX13333adevXrlepo5gFtnMe7UFegAAAAAgBvimjQAAAAAMBGmOwIAgFuSmpp6w5vX+Pv75+kzCgHAHRHSAADALVm7dq3Gjh173THz5s1T06ZN71BFAFC4cU0aAAC4JefPn9fRo0evO+buu++Wv7//HaoIAAo3QhoAAAAAmAg3DgEAAAAAEyGkAQAAAICJcOOQ28wwDGVmXp1RarVanP9G0UWf3QN9LvrosXugz+6BPrsHs/fZarXIYrHkaiwh7TbLzDQUE5Mku92qgABfxccnKyMjs6DLwm1Cn90DfS766LF7oM/ugT67h8LQ51KlfGWz5S6kMd0RAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQBAAAAgIkQ0gAAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQBAAAAgIkQ0gAAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAUCikpKfr22w0FXQYAALcdIQ0AUCikpqZo48av87Stw+HI52oAALh97AVdwK367bffNGfOHP300086cuSIgoODtWbNGpcx/fr103fffZdt27Vr1yokJMT5OCEhQa+//ro2bNig9PR0tWrVSuPHj1fZsmVv+/MAALP57bcT+vzzVbpy5YokqV27TvLz89Pq1SuUlnZFdrtdXbs+pGrVqis2NkYTJ76lFi1a6eDBA7py5Yp6935UP//8k44dOyKHI1N///tjKleuvI4dO6qVK5epYsWKOnPmjOx2u3r27K2KFSvp2LGj+uyzFRox4p+SpHPnftfcubM0duxLWr78U6WmpmrixLdktVo1fPjzio+P1+rVyxUbG6P09HTVrl1HHTp0liS9/vorql8/QseOHVHp0oF69NF+BfZaAgBwMwp9SDty5Ig2bdqk+vXrKzMzU4Zh5DiuQYMGeuGFF1yWVapUyeXxiBEjdPToUb388ssqVqyYJk6cqAEDBmjZsmWy2wv9SwUAuZacnKSPPpqjvn37Kzg4RIZhKCkpSZMnv6O//a23wsJq6vjxKM2f/4FGjx4vSUpJSVXFipXVvn0n7d69U7NnT1f//k+ra9cHtWnTN/rqqy/Vr19/SVJ09Dl16/aQ+vQJ1U8//aiFC+dp1Kix162pR49emjjxLWeAk6QlSxaqTZu2Cg6uIYfDoQ8/nK2ffvpR9euHS5KSkpI0dOhIWSyW2/I6AQBwOxT65NGmTRu1bdtWkjRmzBjt378/x3F+fn4KDw+/5n727t2rrVu3as6cOYqMjJQkVa9eXZ06ddL69evVqVOnfK8dAMzEsFiUku5QcmqGTp04rsCyZRUcfHW2gcViUUJCvCwWi8LCakqSqlcPVvHiJXT27BmVLFlSHh521alTV5JUsWJlFSvmqRo17pIkVa5cRXv3fu88VkBAgO66K1SSVL9+uJYvX6zLly/fVL1XrlzR0aOHlZiY8Kdlabp48bzzcaNGTQhoAIBCp9CHNKs1fy6r27x5s/z8/NSyZUvnsuDgYNWqVUubN28mpAEo0hwWi95btk97D1+QJKVePiWfKxfksFhku8YMBUkuAejPMw6sVqvsdo8/jbPK4ci8bg0Wi0VWq1WZmX+MS09Pv2HtQ4aMkIeHR47rPD09b7g9AABm4zY3Dvnuu+8UHh6uunXrqm/fvtq9e7fL+qioKFWvXj3bb1yDg4MVFRV1J0sFgDvK+EtAkyTP4mV15uw5vT7zCxkWiwzDUIkSfjIMQ0eOHJIknThxXAkJ8apQoeJNHzM2NlZHjx6RJO3b96OKFy8hf39/lS5dWrGxsUpMTJQk/fDDHuc2xYoVU1paujIyMpyPQ0Lu0rff/nEzkfj4uJs+IwcAgNkU+jNpudG4cWN1795d1apV0/nz5zVnzhw98cQTmj9/viIiIiRJ8fHxKlGiRLZt/f39rzmFMrfsdqtstqt5OOtvFE302T0UtT7HpzpcApokWe3FVPquNtq15Su9Hb9PnnarOnTopP79n9KqVcv0+eerZbfb1b//U/L19daVKymyWCyy27NeG4us1j8e2+1WWa1Z3w8tKl++nPbu3a01a1bIZrPpscf6y8PDplKlAtSmzf2aNu1dlSjhp5o1azn34+dXQo0bN9GkSW+pWLFiGjFilPr1e0yrVq3Uu+++KYvFIk/PYurZ82HZ7aWc22XVcDOKWo+RM/rsHuizeyhqfbYY17rTRiGUdU3aX+/u+FfJycnq0qWLQkJCNGvWLEnSE088IavVqjlz5riMfeWVV7Rt2zZ9+eWXearJMAyuhwBgaod+i9GoyVuuuf7t4a0UVrVU/h3v0CF9+umnGj9+fL7tEwCAosQtzqT9lY+Pj+655x6X4OXn56dz585lGxsXFyd/f/88Hysz01B8fLJsNqv8/LwVH59yw+syUHjRZ/dQ1Prs5Xn9/wq8PO2KjU3Kt+PFx6coNTU9X/eZ34paj5Ez+uwe6LN7KAx99vPzzvWZPrcMaTkJDg7Wjh07sp35On78uEJDQ29p3xkZf3yhOByZLo9RNNFn91BU+uztYVVEWKD2HrqQbV1EWKC8Paz5+jyrVQvRP/4xqlC8dkWlx7g++uwe6LN7KCp9LhqTNm9ScnKyNm7cqLp16zqXtW7dWnFxcdqxY4dz2fHjx3XgwAG1bt26IMoEgDvCYhga3KOeIsICXZZHhAVqcI96shSdWfEAABQKhf5MWkpKijZt2iRJOnPmjBITE7Vu3TpJUpMmTRQVFaXZs2frgQceUMWKFXX+/HnNnTtXFy5c0KRJk5z7iYiIUGRkpMaNG6cXXnhBxYoV07vvvquwsDC1a9euQJ4bANwpNsPQ0B71nJ+T5uNll7eHjYAGAEABKPQh7dKlS/rHP/7hsizr8bx581SuXDmlp6fr3Xff1eXLl+Xt7a2IiAj95z//Ub169Vy2mzhxol5//XW99NJLysjIUGRkpMaPH+/y2T8AUFRZDEM+dqt8iv//zxYjoAEAUCCK1N0dzcjhyFRMTJLsdqsCAnwVG5tUJObJImf02T3Q56KPHrsH+uwe6LN7KAx9LlXKN9c3DnHLa9IAAAAAwKwIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZS6EPab7/9ppdeekndu3dX7dq11aVLlxzHffrpp2rfvr3q1q2rbt266dtvv802JiEhQePGjVOTJk0UERGh4cOH6/z587f7KQAAAACAU6EPaUeOHNGmTZtUtWpVhYSE5Djm888/17/+9S917NhRs2bNUnh4uIYOHaoff/zRZdyIESO0bds2vfzyy3r77bd1/PhxDRgwQBkZGXfgmQAAAACAZC/oAm5VmzZt1LZtW0nSmDFjtH///mxjJk+erM6dO2vEiBGSpGbNmunw4cOaNm2aZs2aJUnau3evtm7dqjlz5igyMlKSVL16dXXq1Enr169Xp06d7swTAgAAAODWCv2ZNKv1+k/h1KlTOnHihDp27OiyvFOnTtqxY4fS0tIkSZs3b5afn59atmzpHBMcHKxatWpp8+bN+V84AAAAAOSg0Ie0G4mKipJ09azYn4WEhCg9PV2nTp1yjqtevbosFovLuODgYOc+AAAAAOB2K/TTHW8kLi5OkuTn5+eyPOtx1vr4+HiVKFEi2/b+/v45TqG8GXa7VTbb1Tyc9TeKJvrsHuhz0UeP3QN9dg/02T0UtT4X+ZBW0KxWiwICfJ2P/fy8C7Aa3Cn02T3Q56KPHrsH+uwe6LN7KCp9LvIhzd/fX9LV2+sHBgY6l8fHx7us9/Pz07lz57JtHxcX5xyTF5mZhuLjk2WzWeXn5634+BQ5HJl53h/MjT67B/pc9NFj90Cf3QN9dg+Foc9+ft65PtNX5ENacHCwpKvXnGX9O+uxh4eHKleu7By3Y8cOGYbhcl3a8ePHFRoaeks1ZGT88YXicGS6PEbRRJ/dA30u+uixe6DP7oE+u4ei0ueiMWnzOipXrqxq1app3bp1LsvXrl2r5s2by9PTU5LUunVrxcXFaceOHc4xx48f14EDB9S6des7WjMAAAAA91Xoz6SlpKRo06ZNkqQzZ84oMTHRGciaNGmiUqVKadiwYRo1apSqVKmipk2bau3atdq3b58WLFjg3E9ERIQiIyM1btw4vfDCCypWrJjeffddhYWFqV27dgXy3AAAAAC4H4thGEZBF3ErTp8+rfvvvz/HdfPmzVPTpk0lSZ9++qlmzZqls2fPqnr16nruued03333uYxPSEjQ66+/rq+++koZGRmKjIzU+PHjFRQUlOf6HI5MxcQkyW63KiDAV7GxSUXiFCxyRp/dA30u+uixe6DP7oE+u4fC0OdSpXxzfU1aoQ9pZkdIcy/02T3Q56KPHrsH+uwe6LN7KAx9vpmQVuSvSQMAAACAwoSQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAADIJYfDcduPYb/tRwAAAACAArRz53adOXNKf/tbb0VHn9M777ypp58eqNDQmtqw4UtJUmpqqo4fPyaHw6FixbzUs2dvBQaWlSSNHj1Sbdu206FDB1W9eoi6dOl+W+slpAEAAAAo0u66K1QbN34tSTpy5JCqVq2mI0cOKzS0pg4fPqROnbqqTJlAZ/j68ccftHr1Cj311EDnPqxWq4YNe+6O1EtIAwAAAFDkGBaLUtIdSk7NkI9/KRmSLl26qCNHDqtjx85as2aVrly5ovPno1W5chXt2/ejtm3boitXrsgwDKWkJLnsr1GjpnesdkIaAAAAgCLFYbHovWX7tPfwBeey4snFdfDwr7p48YKCg2vIMKSff/5JVatWU3x8vFauXKZhw55TmTJl9PvvZzV9+hSXfRYrVuyO1c+NQwAAAAAUGUYOAU2SLqT6acZHy1SpSlVJUkhIDX311TrVqHGXUlNTZLPZ5OfnJ8MwtH37loIo3YkzaQAAAACKjJR0R7aAJknF/Mrr92MbVaV6DUlSaGiYNm/eqBo1QlW+fAXVrx+hd955Q76+vrr77rp3umwXFsMwjAKtoIhzODIVE5Mku92qgABfxcYmKSMjs6DLwm1Cn90DfS766LF7oM/ugT67hz/3+dzlVI2euvWaYycMjVSZ4p53sLqrSpXylc2Wu4mMTHcEAAAAUGT4eF1/suCN1psBIQ0AAABAkeHtYVNEWGCO6yLCAuXtYbvDFd08QhoAAACAIsNiGBrco162oBYRFqjBPerJUgiu9jL/uT4AAAAAuAk2w9DQHvX++Jw0L7u8PWyFIqBJhDQAAAAARZDFMORjt8on6yYhhSSgSUx3BAAAAABTIaQBAAAAgIkQ0gAAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQBAAAAgIkQ0gAAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQBAAAAgIkQ0gAAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQBAAAAgIkQ0gAAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQBAAAAgIkQ0gAAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQBAAAAgIkQ0gAAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQhT86cOa0ff/zBZdno0SOVkpJSQBUBAAAARQMhDXny++9ns4W0/OBwOPJ9nwAAAEBhYi/oAnDnjR49Uu3bd9KBA/uVmJigrl0f0vnz0dq//yelpKSqZ8/eCgmpIUn64Yc92rTpG0mSv39J/e1vD8tms2v9+i+UmpqqiRPfUuXKVfW3vz0sSdq+fasOHPhZiYmJatu2vRo3bipJunjxglavXqGkpERlZGSoSZPmatmylbOetm3b6dChg6pePURdunQvgFcFAAAAMAdCmpsqVsxTw4aN1JEjh/XRR3P04IN/0/Dhz+unn37U2rWrNWzYczp37nd9/vkqDR/+vPz9S+rrr7/S0qWL9dRTA9WuXUft379P/fs/7bJfu92uYcOe0/nz0Zo8+f/UoEEjWSwWLVw4T3369FXZskFKS0vTtGkTVaVKVVWuXEWSZLVaNWzYcwXxUgAAAACmQkhzE4bFopR0h5JTM+QwDNWr30CSVKlSZaWlpal+/QhJUpUqVXTx4gVJ0tGjRxQWVkv+/iUlSc2bt9SGDV8qMzPzmseJiGgoSSpbNkg2m1UJCQm6ciVV0dHntHDhPOe41NSry7JCWqNGTfP9OQMAAACFESHNDTgsFr23bJ/2Hr4avs4cu6Q5XxzS8N6NZbVevSzRw8NDkmSxWOVw5BzCLBbLDY+VtZ+sfRlGpgxD8vb20YgR/7zmdsWKFcv18wEAAACKMm4cUsQZfwloWX46fFHvLd8n4zrBq0aNu3To0EHFx8dJknbu3KYaNe6S1WpVsWLFdOXKlVzVEBgYKC8vL+3evcu57OLFi0pOTsrDMwIAAACKNs6kFXEp6Y5sAS3L3kMXlNquxjW3LVeuvDp37q45c2ZIunrjkJ49e0uSatQI1ebNG/XuuxNUpUo1541DcmKz2dS//wB99tkKbd26SQ5HpooXL65HHul7C88MAAAAKJoshmEYBV1EUeZwZComJkl2u1UBAb6KjU1SRsa1r+nKbxcT0zR66tZrrp8wNFJlinvesXqKuoLqM+4s+lz00WP3QJ/dA312D4Whz6VK+cpmy91ERqY7FnE+Xtc/WXqj9QAAAADuLEJaEeftYVNEWGCO6yLCAuXtYbvDFQEAAAC4HkJaEWcxDA3uUS9bUIsIC9TgHvVkYbYrAAAAYCrMdXMDNsPQ0B71nJ+T5uNll7eHjYAGAAAAmBAhzU1YDEM+dqt8sm4SQkADAAAATInpjgAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACbiFiFt+fLlCgsLy/bn7bffdhn36aefqn379qpbt666deumb7/9toAqBgAAAOCu3OoW/LNnz1aJEiWcj4OCgpz//vzzz/Wvf/1LgwYNUrNmzbR27VoNHTpUH3/8scLDwwugWgAAAADuyK1C2t13361SpUrluG7y5Mnq3LmzRowYIUlq1qyZDh8+rGnTpmnWrFl3sEoAAAAA7swtpjveyKlTp3TixAl17NjRZXmnTp20Y8cOpaWlFVBlAAAAANyNW4W0Ll26qFatWrr//vs1Y8YMORwOSVJUVJQkqXr16i7jQ0JClJ6erlOnTt3xWgEAAAC4J7eY7hgYGKhhw4apfv36slgs+uabbzRx4kRFR0frpZdeUlxcnCTJz8/PZbusx1nr88put8pmu5qHs/5G0USf3QN9LvrosXugz+6BPruHotbnmwppaWlpWr16tY4dO6aAgAB16NBBVapUyTZu+/btmj59uubNm5dvhd6KVq1aqVWrVs7HkZGRKlasmD766CMNGjToth7barUoIMDX+djPz/u2Hg/mQJ/dA30u+uixe6DP7oE+u4ei0udch7SEhAT16dNHx44dcy6bPHmynnzySY0YMUJW6x+p9eLFi9q9e3f+VprPOnbsqA8++EAHDx6Uv7+/pKvPMTAw0DkmPj5ekpzr8yIz01B8fLJsNqv8/LwVH58ihyPz1oqHadFn90Cfiz567B7os3ugz+6hMPTZz88712f6ch3S3nvvPZ08eVJvvPGGHnjgAV24cEGzZs3SzJkz9euvv2rSpEny9i6cyTU4OFjS1WvTsv6d9djDw0OVK1e+pf1nZPzxheJwZLo8RtFEn90DfS766LF7oM/ugT67h6LS51xP2vz222/1yCOP6MEHH5Svr6+qVaum//73v3rrrbe0a9cuPf7447p8+fJtLDV/rV27VjabTbVr11blypVVrVo1rVu3LtuY5s2by9PTs4CqBAAAAOBucn0m7dy5cwoNDc22vGvXripfvrwGDx6sRx99VLNnz87XAvPDU089paZNmyosLEyS9PXXX2vJkiV67LHHnNMbhw0bplGjRqlKlSpq2rSp1q5dq3379mnBggUFWToAAAAAN5PrkFamTBn9/vvvOa5r1KiR5s2bp6efflqPPPKIunXrlm8F5ofq1atr2bJlOnfunDIzM1WtWjWNGzdO/fr1c47p0qWLUlJSnFM4q1evrqlTpyoiIqIAKwcAAADgbiyGYRi5GThy5EhFRUVp1apV1xxz8uRJPfnkkzpz5owk6eDBg/lTZSHmcGQqJiZJdrtVAQG+io1NKhLzZJEz+uwe6HPRR4/dA312D/TZPRSGPpcq5ZvrG4fk+pq0jh07Kjo6+rp3baxSpYo++eSTHKdFAgAAAABuLNfTHdu1a6d27drdcFyZMmWue7YNAAAAAHBtReMjuQEAAACgiCCkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmEiub8F/LUlJSYqPj1dOn4ldoUKFW909AAAAALiVPIW0K1euaOrUqVq6dKkuX758zXEHDx7Ma10AAAAA4JbyFNJefvllrVy5Um3btlXDhg3l7++f33UBAAAAgFvKU0j76quv1KtXL73yyiv5XQ8AAAAAuLU83TjEYrGodu3a+V0LAAAAALi9PIW0+++/X9u3b8/vWgAAAADA7eUppA0ePFinT5/Wv/71L+3fv18xMTG6fPlytj8AAAAAgJuTp2vS2rVrJ0k6cOCAli5des1x3N0RAAAAAG5OnkLakCFDZLFY8rsWAAAAAHB7eQppw4YNy+86AAAAAADK4zVpf5WamqrU1NT82BUAAAAAuLU8nUmTpLNnz2rKlCnatGmTYmNjJUkBAQG65557NHToUFWsWDHfigQAAAAAd5GnkHbs2DE9+uijSkhIUIsWLRQSEiJJioqK0qpVq/Ttt99q4cKFCg4OztdiAQAAAKCoy1NIe+edd2S1WrVixQqFhYW5rDt8+LD69++vd955R9OmTcuXIgEAAADAXeTpmrTdu3erX79+2QKaJIWGhurvf/+7vvvuu1suDgAAAADcTZ5CWkZGhry8vK653tvbWxkZGXkuCgAAAADcVZ5CWq1atfTpp58qISEh27rExEQtXbpUtWvXvuXiAAAAAMDd5Plz0gYMGKCOHTuqR48eqlatmiTp+PHjWrFihS5fvqyXXnopP+sEAAAAALeQp5DWvHlzzZw5UxMmTNDMmTNd1tWqVUtvvfWWmjVrli8FAgAAAIA7yfPnpLVo0UIrV67UhQsXdPbsWUlShQoVFBgYmG/FAQAAAIC7yXNIyxIYGEgwAwAAAIB8kquQtnLlSklS9+7dZbFYnI9v5MEHH8xjWQAAAADgnnIV0saMGSOLxaJOnTrJ09NTY8aMueE2FouFkAYAAAAANylXIe3rr7+WJHl6ero8BgAAAADkr1yFtIoVK173MQAAAAAgf9zyjUOyGIahnTt3Ki0tTQ0bNlTx4sXza9cAAAAA4DbyFNLeffdd/fDDD5o/f76kqwHtySef1M6dO2UYhipUqKAPP/xQVapUyddiAQAAAKCos+Zloy+//FL16tVzPl63bp127NihESNGaMaMGXI4HJoyZUq+FQkAAAAA7iJPZ9Kio6NVtWpV5+OvvvpKNWrU0MCBAyVJjzzyiBYtWpQ/FQIAAACAG8nTmTS73a60tDRJV6c67tixQ61atXKuL126tGJjY/OnQgAAAABwI3kKaXfddZdWr16tuLg4LVu2TJcvX9Y999zjXH/27FkFBATkW5EAAAAA4C7yNN1xyJAhGjRokJo1ayZJatCggfPfkrRp0ybVrVs3fyoEAAAAADeSp5DWsmVLrVixQtu2bZOfn586derkXBcXF6dGjRqpTZs2+VYkAAAAALiLPH9OWo0aNVSjRo1sy/39/TVu3LhbKgoAAAAA3NUtf5h1UlKS4uPjZRhGtnUVKlS41d0DAAAAgFvJU0i7cuWKpk6dqqVLl+ry5cvXHHfw4MG81gUAAAAAbilPIe3ll1/WypUr1bZtWzVs2FD+/v75XRcAAAAAuKU8hbSvvvpKvXr10iuvvJLf9QAAAACAW8vT56RZLBbVrl07v2sBAAAAALeXp5B2//33a/v27fldCwAAAAC4vTyFtMGDB+v06dP617/+pf379ysmJkaXL1/O9gcAAAAAcHPydE1au3btJEkHDhzQ0qVLrzmOuzsCAAAAwM3JU0gbMmSILBZLftcCAABwQ+vXr9N9990vDw+Pgi4FAG6LPIW0YcOG5XcdAAAAkiSHwyGbzXbN9Rs2fKlWre656ZB2o/0CgFnkKaT9VUJCgnx8fPjGBwCAG0lPT9fixR/r3LlzstmsKl68hAYMeFY//LBH27ZtkcPhULFixdS9ew9VqFBRkvTttxu0d+/3slgs8vDw1DPPDNapUye1YsVSVa1aTWfOnNJ99z2gihUravXqFUpKSlRGRoaaNGmuli1badmyJZKk99+fLKvVqqefflZHjhzS1q2b5XA4ZBiZat++k2rXriNJmj59qsqXr6BTp07Kw8NDQUFBKlHCX/ff/4AkKTo6Wm+++ZZGjx7PzzEATCPPIe3nn3/WxIkTtWfPHqWnp2vOnDlq3ry5YmJi9OKLL6p///5q2rRpftYKAABM5NChg0pNTdWoUWMkScnJSTpx4rj27v1ezz47THa7XVFRx7Rw4XyNGjVGe/Z8p/379+nZZ4fL29tbycnJstuv/ihy4UK0evToqV69+igzM1NTp76rPn36qmzZIKWlpWnatImqUqWq/va3h7Vr1w7nPiQpLKymwsMbyGKxKDY2RlOnvqvQ0JrOfV+8eEGDBg2V3W7XhQvnNXv2dN133/2SrNq4caOaNWtBQANgKnkKaT/88IMef/xxBQUFqVu3bvr000+d60qVKqXExEQtXryYkAYAQBFjWCxKSXcoOTVDJQPLKfp8tFasWKrg4BDVrFlLv/zys37//aymTn3XuU1KSrLS09N18OABNWvWwhmufHx8nGNKlSqj4OAakqQLF84rOvqcFi6c51yfmpqq6Ohzqly5SraaLl26pPXrF+jy5cuy2axKTk5RTMwllS0bJEmKiGjoDGyBgWVVtmyQfvnlZ9WuXVu7d+/W8OGj8v+FAoBbkKeQ9u677yokJERLlixRYmKiS0iTpKZNm2rFihX5UiAAADAHh8Wi95bt097DF5zL6t3VVTXCPBV15LA+/3y1QkPD1LBhY3Xs2OWm9l2smKfz34YheXv7aMSIf+Zq24UL56tjx86qVy9ckvTvf49Tenq6c72nZzGX8ZGR92jjxq+VmpqsWrVqqUSJEsrIyLypegHgdsrT56T9/PPP6tGjhzw9PXO8y2NQUJAuXrx4y8UBAABzMHIIaI60JP14+II2HjLUqUt3SVKDBo20d+/3io2NvbqdYejUqZOSpLvvrqOdO7crJSVFkpSSkqLMzOzhKDAwUF5eXtq9e5dz2cWLF5WcnCRJKlasmFJTU5zrUlKSVapUaUnSDz/sce7/WkJDw5SQkKANG9br3nvvvdmXAgBuuzydSbPb7Tl+U80SHR3tMoUBAAAUbinpDpeAJknpybGKP/29vjxoKOloeTVo0EjBwTXUqVNXzZv3gTIzHXI4HKpZs7YqV66iBg0aKS7usqZNmySbzSpPz2IaMODZbMey2Wzq33+APvtshbZu3SSHI1PFixfXI4/0lSS1bn2vZs16X56ennr66WfVrdtDmj9/rry9fVSjRg2VLFnyus/FYrGoceOm2rfvB4WEhCg2NinfXicAyA8WwzCMm93oqaeeUnJyshYtWqTY2Fg1b95cc+fOVfPmzZWcnKwuXbqoTp06mjx58u2ouVBxODIVE5Mku92qgABfxcYmMaWiCKPP7oE+F330OLuLiWkaPXXrNddPGBqpMsU9r7nebObOnaUGDRqobdt76XMRx/vZPRSGPpcq5SubLXcTGfM03XH48OHav3+/nnnmGW3evFmSdOjQIX366afq0aOHYmJiNHjw4LzsGgAAmJCP1/Un39xovVmcOnVSb775X1ksFkVENCzocgAgR3k6kyZJO3bs0Msvv6zffvvNZXmVKlX02muvqUmTJvlSYGHHmTT3Qp/dA30u+uhxdobFoqnL92nvoQvZ1kWEBWpoj3qy5O1HigJDn90DfXYPhaHPN3MmLc+/9mrevLm+/PJLHTx4UCdOnJBhGKpcubLq1KmT481EAABA4WUxDA3uUU/v/SWoRYQFanAhDGgAYGa3PDehVq1aqlWrVn7UAgAATMxmGBrao57zc9J8vOzy9rAR0AAgn91SSDt79qxOnTql+Ph45TRrsl27dreyewAAYDIWw5CP3SqfrJuEENAAIN/lKaSdPXtW48aN065dVz+/JKeAZrFYdPDgwVurDgAAAADcTJ5C2gsvvKAff/xRzzzzjOrVq6cSJUrkd10AAAAA4JbyFNJ++uknDRgwQMOHD8/vegAAAADAreXpc9LKlSsnPz+//K4FAAAAANxenkLak08+qWXLliklJSW/6wEAAAAAt5an6Y59+vSRw+FQu3bt1L59e5UrV042m81ljMViUf/+/fOjRgAAAABwG3kKaYcPH9acOXN04cIFLViwIMcxhDQAAAAAuHl5CmkvvfSSEhIS9Morr3B3RwAAAADIR3kKaQcPHtSwYcP08MMP53c9AAAAAODW8nTjkEqVKuV3HQAAAAAA5TGkDRs2TAsXLtTvv/+e3/UAAAAAgFvL03THPXv2qESJEurQoYOaN2+u8uXLZ7u7oySNHz/+lgsEAAAAAHeSp5D25zs6bty4MccxFouFkAYAAAAANylPIe3XX3/N7zoAAAAAAMrjNWkAAAAAgNuDkAYAAAAAJpKr6Y41a9aU1WrVjz/+KE9PT9WsWVMWi+W621gsFh04cCBfigQAAAAAd5GrkDZkyBBZLBbZ7XaXxwAAAACA/JWrkDZs2LDrPgYAAAAA5A+uSQMAAAAAE7npW/CnpaVp1apV2rZtm06ePKmkpCT5+vqqatWqatWqlbp06SJPT8/bUSsAAAAAFHk3FdIOHTqkwYMH6+zZszIMQyVKlJCPj49iYmJ04MABrVu3TtOnT9f777+vkJCQ21UzAAAAABRZuQ5pSUlJevbZZxUTE6ORI0eqe/fuCgoKcq6Pjo7WypUr9f7772vQoEFatWqVfHx8bkvRAAAAAFBU5fqatOXLl+v333/XjBkz9Mwzz7gENEkKCgrSwIED9f777+v06dNasWJFvhcLAAAAAEVdrkPaxo0b1bJlSzVt2vS645o3b64WLVrom2++ueXiAAAAAMDd5DqkHT58WE2aNMnV2GbNmunw4cN5LgoAAAAA3FWuQ1pcXJwCAwNzNbZMmTKKi4vLc1EAAAAA4K5yHdLS0tJkt+fuPiM2m03p6el5LgoAAAAA3NVN3YL/zJkz+uWXX2447vTp03kuCAAAAADc2U2FtEmTJmnSpEk3HGcYhiwWS56LAgAAAAB3leuQ9vrrr9/OOgAAAAAAuomQ9tBDD93OOgAAAAAAuokbhwAAAAAAbj9CGgAAAACYCCENAAAAAEyEkAYAAAAAJkJIAwAAAAATIaQBAAAAgIkQ0v7i2LFjeuKJJxQeHq6WLVtqwoQJSktLK+iyAAAAALiJXH9OmjuIi4vT448/rmrVqmnKlCmKjo7WG2+8odTUVL300ksFXR4AAAAAN0BI+5NPPvlESUlJmjp1qkqWLClJcjgc+s9//qOBAwcqKCioYAsEAAAAUOQx3fFPNm/erObNmzsDmiR17NhRmZmZ2rZtW8EVBgAAAMBtENL+JCoqSsHBwS7L/Pz8FBgYqKioqAKqCgAAAIA7Ybrjn8THx8vPzy/bcn9/f8XFxeV5v3a7VTbb1Tyc9TeKJvrsHuhz0UeP3QN9dg/02T0UtT4T0m4zq9WigABf52M/P+8CrAZ3Cn12D/S56KPH7oE+uwf67B6KSp8JaX/i5+enhISEbMvj4uLk7++fp31mZhqKj0+WzWaVn5+34uNT5HBk3mqpMCn67B7oc9FHj90DfXYP9Nk9FIY++/l55/pMHyHtT4KDg7Nde5aQkKALFy5ku1btZmRk/PGF4nBkujxG0USf3QN9LvrosXugz+6BPruHotLnojFpM5+0bt1a27dvV3x8vHPZunXrZLVa1bJlywKsDAAAAIC7IKT9SZ8+feTr66shQ4Zo69atWrZsmSZMmKA+ffrwGWkAAAAA7ghC2p/4+/vro48+ks1m05AhQ/TOO++oZ8+eGjNmTEGXBgAAAMBNcE3aX4SEhOjDDz8s6DIAAAAAuCnOpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ3ALXM4HAVdAgAAQJFhL+gCABSs0aNHqn37Tjpw4GclJiaqbdv2aty4qSTp9ddf0WOPPamKFStJkiZPfkedO3dXSEgNTZ8+VeXLV9CpUyfl4eGhv//9cS1aNF8JCfGyWCyqWLGSHn74UUnSpk3fat++vXI4MlWiRAn16NFLAQGlCuw5AwAAmBkhDXBDhsWilHSHklMz5DAM2T3sGjbsOZ0/H63Jk/9PDRo0ks1mu+F+Ll68oEGDhsput2vLlo0qVaq0Bgx4VpKUnJwkSdq793tduBCtIUNGyGq16ocf9mjFiqV68slnbuMzBAAAKLwIaYCbcVgsem/ZPu09fEGSdObYJVU4461Ii0VlywbJZrMqISFBJUuWvOG+IiIaym6/+m2kSpVq2rJlk9asWanq1WsoLKymJOmXX37WqVMnNXnyO5KkzMzM2/PEAAAAighCGuBGjL8EtCw/H7us95bv09Ae9WSxWGUYV4OU1WqTYRjOcenpGS7beXoWc/67atVqGjFilI4cOaL9+3/S+vVr9Y9/jJJhSPfd11bNmrW4jc8MAACg6ODGIYAbSUl3ZAtoWfYeuqCUdNcbgJQpU0anTv0mSTp58jddvHj+mvuOibkkT89iql8/XN27/00XLlzQlStXdPfddbRz53bn9MeMjAydOXM6n54RAABA0cOZNMCNJKdm3NT6du06avHihdq5c7uqVKmmoKBy19z22LGj2rJlo6xWqxyOTHXq1FXe3t5q0KCRkpOTNWPGNEmSw5Gpxo2bOm9GAgAAAFcW489zmZDvHI5MxcQkyW63KiDAV7GxScrI4JqcosrsfU7OyNTQtzdec/3UUffKx84J9hsxe59x6+ixe6DP7oE+u4fC0OdSpXxls+Xu5yx+GgPciLeHTRFhgTmuiwgLlLfHje/oCAAAgNuLkAa4EYthaHCPetmCWkRYoAb3qCcLJ9YBAAAKHNekAW7GZhga2qOe83PSfLzs8vawEdAAAABMgpAGuCGLYcjHbpVPcc+rCwhoAAAApsF0RwAAAOAOmTjxLV25kprjusmT39GxY0dvaf979nyn8+ejb2kfKHiENAAAAOAmORyOGw/KwYgR/1SxYl75XM0froa0a3+uKQoHpjsCAAAA/9/o0SPVpk1b/frrQaWlXVHbtu3VoEEj57q2bdvp0KGDql49RA880F6ffbZSv/9+VhkZGapSpaq6d/+b7Ha7vv56vfbu/V52+9Uftx9//CkFBJTS6NEj9Z///E/e3t46ceK4Vq5cKocjU5UrV1Zm5h+3jo+Pj9fq1csVGxuj9PR01a5dRx06dJYkvf76K2rYsLEOHz6khIR4NWnSTPff307ffbdTp0+f0mefrdCGDevUoUNn1axZ+86/iLhlhDQAAADgTywWi0aMGKVLly5q8uT/U/XqwQoIKCVJslqtGjbsOUnSsmWLVb16iHr27CPDMLR06WJt27ZZjRs30+bN32r8+Ffk4eGhtLQ0WSwWl2NkZGRo4cJ56tWrj+66K0yHD/+qPXt2O9cvWbJQbdq0VXBwDTkcDn344Wz99NOPql8/XJKUkpKioUNHKCkpUW+++V81atRETZo00w8/7FFk5D2qU6funXmxcFsQ0gAAAODWDIvFeddjh2GocdPmkqTSpcuoevVgRUUdU8OGV0Nao0ZNndv98st+/fbbCW3ZslGSlJ6eLqvVKi8vL5UpE6hPPlmgu+4KU82atVWyZEmXY164cF4Wi0V33RUmSQoNranSpUtLkq5cuaKjRw8rMTHBOf7KlTRdvPjHNMaIiAaSJF/f4ipVqrRiYmLk7+96DBRehDQAAAC4LYfFoveW7dPewxckSWeOXdKczw/oub6Rsv3/ux//+SxYsWLFnP82DEP9+j2hwMCy2fY7ZMgInThxXFFRRzVt2kQ98kg/BQeH3KAa17NtQ4aMkIeHR44jbbY/foy3Wi0uUyVR+HHjEAAAALgl4y8BLcuunTv13vJ9irkcqxMnjqt69eAct7/77jrauPEb501EkpOTdfHiRV25kqrExAQFB4eobdv2qlatus6ePeOybWBgWRmGoaNHj0iSjhw5pEuXLkq6GgRDQu7St99+7RwfHx+ny5cv3/A5eXl5KTU1JdevAcyJM2kAAABwSynpjmwBTZJkGPpy2WwlHC6rbt0ecl6P9ldduz6kL774TBMnvi2r1SKLxarOnbvKbrdrwYIPlZZ2RRaLRWXKBKphw8Yu29rtdj366GNauXKpMjMzValSFVWoUMG5/pFH+umzz1bqnXfelMUieXoWU48evbJNm/yrpk2ba82aVdq6dRM3DinELIbBp9jeTg5HpmJikmS3WxUQ4KvY2CRlZHA6uqiiz+6BPhd99Ng90Gf3cL0+X0xM0+ipW12Wnflurso3+Lusdk9NGBqpMsU972S5yKPC8H4uVcpXNlvuJjIy3REAAABuycfr+pPKbrQeuF0IaQAAAHBL3h42RYQFuiyr2OQJWe2eiggLlLeHrYAqg7sjpAEAAMAtWQxDg3vUyxbUIsICNbhHPVm4KggFhHO4AAAAcFs2w9DQHvWcn5Pm42WXt4eNgIYCRUgDAACAW7MYhnzsVvlk3SSEgIYCxnRHAAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIm4R0saMGaOwsLBsfzZv3uwyLi0tTW+++aZatmyp8PBwPfHEE4qKiiqgqgEAAAC4I3tBF3CnVK5cWW+//bbLspCQEJfHr732mtauXasxY8YoKChI06dPV//+/fX555+rRIkSd7JcAAAAAG7KbUKal5eXwsPDr7n+3LlzWrp0qf7973+rZ8+ekqS6devqvvvu0yeffKIBAwbcoUoBAAAAuDO3mO6YG1u3blVmZqY6dOjgXFayZEm1bNky27RIAAAAALhd3Cak/fbbb2rYsKHq1KmjHj16aMOGDS7ro6KiVLp0afn7+7ssDwkJ4bo0AAAAAHeMW0x3rFWrlurWrasaNWooISFBixYt0pAhQzRp0iTnmbP4+Pgcrzvz8/NTXFzcLR3fbrfKZruah7P+RtFEn90DfS766LF7oM/ugT67h6LW50IZ0hISEnT+/PkbjqtcubI8PT31+OOPuyxv06aN+vTpo8mTJ7tMb7wdrFaLAgJ8nY/9/Lxv6/FgDvTZPdDnoo8euwf67B7os3soKn0ulCFt3bp1Gj9+/A3HrV27NtsdHCXJarWqXbt2euutt5SamiovLy/5+fkpMTEx29j4+PhsUyBvRmamofj4ZNlsVvn5eSs+PkUOR2ae9wdzo8/ugT4XffTYPdBn90Cf3UNh6LOfn3euz/QVypDWq1cv9erVK1/3GRwcrIsXLyouLs4llEVFRSk4OPiW9p2R8ccXisOR6fIYRRN9dg/0ueijx+6BPrsH+uweikqfi8akzZuUmZmpdevW6a677pKXl5ckKTIyUlarVevXr3eOi4uL09atW9W6deuCKhUAAACAmymUZ9JuxpkzZzRmzBh17txZVatWVVxcnBYtWqT9+/drypQpznHlypVTz549NWHCBFmtVgUFBWnGjBkqUaKE+vTpU4DPAAAAAIA7KfIhzdfXV8WLF9f777+vS5cuycPDQ3Xq1NGsWbPUqlUrl7Hjx4+Xr6+v3nnnHSUlJalBgwaaO3dujnd9BAAAAIDbwWIYhlHQRRRlDkemYmKSZLdbFRDgq9jYpCIxTxY5o8/ugT4XffTYPdBn90Cf3UNh6HOpUr65vnGIW16TBgAAAABmRUgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAC59vLLLyo2NibP22/ZslHx8fHOxzt2bNOmTd9cd5v9+3/WyZMn8nxMAAAKG3tBFwAAcB9bt25WcHAN+fn5SZKaN295w20OHPhZ5ctXUJUq1W5zdQAAmAMhDQBwTb/8sl9ffPGZbDabQkNrOpdfvHhBq1evUFJSojIyMtSkSXO1bNlKkjR69Ei1b99JBw78rMTERLVt216NGzfVhg1fKj4+XgsXzpOHh4d69XpEv/yyX6mpKerW7SGdPHlCK1Ysk2FkyuHIVIsWLRUQUEq//LJfhw8f0vff71aLFq3UpEmzgno5AAC4IwhpAIAcJSYm6tNPF+nZZ4cpKKicdu7cruTkZDkcmVq4cJ769OmrsmWDlJaWpmnTJqpKlaqqXLmKJMlut2vYsOd0/ny0Jk/+PzVo0Eht27bX7t279Oijj6lixUqSrobALN98s0H33HOfwsMbSJKSk5Pl4+Oju++uo/LlK6hVq3vv+GsAAEBBIKQBAFwYFotS0h3a9+sRlQkqr7LlykuGoSZNmmnVquVyODIUHX1OCxfOc26Tmpqq6OhzzpAWEdFQklS2bJBsNqsSEhJUsmTJ6x43JKSGNmxYr4sXLygk5C5Vrx58254jAABmRkgDADg5LBa9t2yf9h6+oJTYk0qK/k1GuX0a3KOerBaLJMkwJG9vH40Y8c9r7sfDw8P5b4vFKsPIvOGxW7W6V3ffXVdHjhzWunWfq1y58nrooZ63/qQAAChkCGkAAElXz6BlBTRJ8iweqMvHY/Xdj0ckSU0qJsnhcMhut8vLy0u7d+9S48ZNJUkXL16Uj4+3fHx8r3sMLy8vXbmSmuO6CxfOKzCwrJo2bS5//5Jat+5zSVKxYl5KTc15GwAAiiJCGgBAkpSS7nAGNEmyeXirZPVIxRz9Rl8e26jKvdvKx8dHNptV/fsP0GefrdDWrZvkcGSqePHieuSRvjc8RsuWrbV06WJ5enqqV69HXNZt27ZFR48ekd1ul9VqUZcu3SVJDRo00uLFC/XLL/vVokUkNw4BABR5FsMwjIIuoihzODIVE5Mku92qgABfxcYmKSPjxtN+UDjRZ/dQVPt8MTFNo6duveb6CUMjVaa45x2sqOAU1R7DFX12D/TZPRSGPpcq5SubLXcfU82HWQMAJEk+XtefXHGj9QAAIH8Q0gAAkiRvD5siwgJzXBcRFihvD9sdrggAAPdESAMASJIshqHBPeplC2oRYYEa3KOeLMyOBwDgjmDuCgDAyWYYGtqjnlLSHUpOzZCPl13eHjYCGgAAdxAhDQDgwmIY8rFb5ZN1kxACGgAAdxTTHQEAAADARAhpAAAAAGAihDQAAAAAMBFCGgAAAACYCCENAAAAAEykUIe0bdu26fnnn1fbtm0VFhamV155JcdxaWlpevPNN9WyZUuFh4friSeeUFRUVLZxx44d0xNPPKHw8HC1bNlSEyZMUFpa2u1+GgAAAADgVKhD2pYtW/Trr7+qcePG8vPzu+a41157TZ9++qlGjhypKVOmKC0tTf3791dCQoJzTFxcnB5//HGlp6drypQpGjlypJYsWaI33njjTjwVAAAAAJBUyD8nbfTo0RozZowkadeuXTmOOXfunJYuXap///vf6tmzpySpbt26uu+++/TJJ59owIABkqRPPvlESUlJmjp1qkqWLClJcjgc+s9//qOBAwcqKCjo9j8hAAAAAG6vUJ9Js1pvXP7WrVuVmZmpDh06OJeVLFlSLVu21ObNm53LNm/erObNmzsDmiR17NhRmZmZ2rZtW77WDQAAAADXUqhDWm5ERUWpdOnS8vf3d1keEhLicl1aVFSUgoODXcb4+fkpMDAwx+vXAAAAAOB2KNTTHXMjPj5eJUqUyLbcz89PcXFxLuNyuq7N39/fZVxe2O1W2WxX83DW3yia6LN7oM9FHz12D/TZPdBn91DU+myqkJaQkKDz58/fcFzlypXl6el5Byq6dVarRQEBvs7Hfn7eBVgN7hT67B7oc9FHj90DfXYP9Nk9FJU+myqkrVu3TuPHj7/huLVr1yokJCRX+/Tz81NiYmK25fHx8S5TIP38/Fzu9pglLi4u21TJm5GZaSg+Plk2m1V+ft6Kj0+Rw5GZ5/3B3Oize6DPRR89dg/02T3QZ/dQGPrs5+ed6zN9pgppvXr1Uq9evfJ1n8HBwbp48WK2sPXXa9CCg4OzXXuWkJCgCxcuZLtW7WZlZPzxheJwZLo8RtFEn90DfS766LF7oM/ugT67h6LS56IxafM6IiMjZbVatX79eueyuLg4bd26Va1bt3Yua926tbZv3674+HjnsnXr1slqtaply5Z3tGYAAAAA7stUZ9Ju1pkzZ/Tzzz9LklJSUnTy5EmtW7dOkpy33C9Xrpx69uypCRMmyGq1KigoSDNmzFCJEiXUp08f57769Omj+fPna8iQIRo4cKCio6M1YcIE9enTh89IAwAAAHDHFOqQtmvXLo0dO9b5eMuWLdqyZYsk6dChQ87l48ePl6+vr9555x0lJSWpQYMGmjt3rstdH/39/fXRRx/p1Vdf1ZAhQ+Tr66uePXtq5MiRd+4JAQAAAHB7FsMwjIIuoihzODIVE5Mku92qgABfxcYmFYl5ssgZfXYP9Lnoo8fugT67B/rsHgpDn0uV8s31jUOK/DVpAAAAAFCYENIAAAAAwEQIaQAAAABgIlyTdpsZhqHMzKsvsc1mNe2H6yH/0Gf3QJ+LPnrsHuize6DP7sHsfbZaLbJYLLkaS0gDAAAAABNhuiMAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAAAAACZCSAMAAAAAEyGkAQAAAICJENLy2bZt2/T888+rbdu2CgsL0yuvvJLjuLCwsGx/WrZsmW3csWPH9MQTTyg8PFwtW7bUhAkTlJaWdrufBm4gt31OS0vTm2++qZYtWyo8PFxPPPGEoqKiso2jz4XDmDFjcnzvbt682WVcbvsOc+L9WLQsX748x/ft22+/7TLu008/Vfv27VW3bl1169ZN3377bQFVjBv57bff9NJLL6l79+6qXbu2unTpkuO43PQ0ISFB48aNU5MmTRQREaHhw4fr/Pnzt/spIBdy0+d+/frl+P4+duyYy7jC2Gd7QRdQ1GzZskW//vqrGjdurLi4uOuO7devn8sXnIeHh8v6uLg4Pf7446pWrZqmTJmi6OhovfHGG0pNTdVLL710W+pH7uS2z6+99prWrl2rMWPGKCgoSNOnT1f//v31+eefq0SJEpLoc2FTuXLlbD/chYSEuDzOTd9hTrwfi67Zs2e7vP+CgoKc//7888/1r3/9S4MGDVKzZs20du1aDR06VB9//LHCw8MLoFpcz5EjR7Rp0ybVr19fmZmZMgwj25jc9nTEiBE6evSoXn75ZRUrVkwTJ07UgAEDtGzZMtnt/JhckHLTZ0lq0KCBXnjhBZdllSpVcnlcKPtsIF85HA7nv++77z7jP//5T47jQkNDjdmzZ193X9OnTzfCw8ON2NhY57JPPvnEqFWrlnHu3Ll8qRd5k5s+//7770atWrWMTz75xLksNjbWCA8PN2bOnOlcRp8LjxdeeMHo3Lnzdcfktu8wJ96PRc+yZcuM0NBQ49KlS9cc065dO+O5555zWda7d2/j6aefvt3lIQ/+/H/wtb4v56anP/zwgxEaGmps2bLFuezYsWNGWFiY8fnnn9+GynEzctPnvn37Gs8888x191NY+8x0x3xmtebfS7p582Y1b95cJUuWdC7r2LGjMjMztW3btnw7Dm5ebvq8detWZWZmqkOHDs5lJUuWVMuWLV2mx9HnoiW3fYc58X50P6dOndKJEyfUsWNHl+WdOnXSjh07mOpqQjf6Pzi3Pd28ebP8/PxcLjcJDg5WrVq1+H5tAvn1M3Vh7TMhrQDNnDlTd999txo1aqQRI0bo7NmzLuujoqIUHBzssszPz0+BgYFc31IIREVFqXTp0vL393dZHhIS4tI/+ly4/Pbbb2rYsKHq1KmjHj16aMOGDS7rc9t3mBPvx6KrS5cuqlWrlu6//37NmDFDDodDkpx9rV69usv4kJAQpaen69SpU3e8Vtya3PY0KipK1atXl8VicRkXHBzM+70Q+e677xQeHq66deuqb9++2r17t8v6wtpnk07CLPoefPBB3XvvvSpTpowOHz6s999/X48++qhWrVrl/OEuPj5efn5+2bb19/e/4fVuKHjx8fE5Xn/k5+fn0j/6XHjUqlVLdevWVY0aNZSQkKBFixZpyJAhmjRpkvPMWW77DnPi/Vj0BAYGatiwYapfv74sFou++eYbTZw4UdHR0XrppZecff1r37Me0/fCJ7c9vdb3a39/f+3fv/82V4n80LhxY3Xv3l3VqlXT+fPnNWfOHD3xxBOaP3++IiIiJBXePhPSbiAhISFXd3+pXLmyPD09c73fN9980/nvxo0bq2HDhurRo4eWLFmiAQMG5KlW5N3t6jPM7Wb7/vjjj7ssb9Omjfr06aPJkye7TG8EYB6tWrVSq1atnI8jIyNVrFgxffTRRxo0aFABVgbgVg0fPtzl8b333qsuXbrovffe06xZswqoqvxBSLuBdevWafz48Tcct3bt2mx3eLsZNWvWVPXq1fXLL784l/n5+SkhISHb2Li4uGxTqXBrbkef/fz8lJiYmG15fHy8S//oc8G51b5brVa1a9dOb731llJTU+Xl5ZXrvsOceD+6h44dO+qDDz7QwYMHnX1NSEhQYGCgc0x8fLwk0fdCKLc99fPz07lz57Jtz/u98PLx8dE999yjL7/80rmssPaZkHYDvXr1Uq9evQrk2DnNlU1ISNCFCxeyXTOBW3M7+hwcHKyLFy9m+ybw12te6HPBKci+w5x4P7qfrL7+9T0aFRUlDw8PVa5cuaBKQx7ltqfBwcHasWOHDMNwuV7p+PHjCg0NvbNF47YprH3mxiEmcfDgQR0/flx169Z1LmvdurW2b9/u/M2PdPU3/1arNccPvoa5REZGymq1av369c5lcXFx2rp1q1q3bu1cRp8Lr8zMTK1bt0533XWXvLy8JOW+7zAn3o/uYe3atbLZbKpdu7YqV66satWqad26ddnGNG/enCnuhVBue9q6dWvFxcVpx44dzjHHjx/XgQMH+H5dSCUnJ2vjxo3Zfp4ujH3mTFo+O3PmjH7++WdJUkpKik6ePOn8JpF1zcqcOXN08uRJNW3aVKVKldKRI0c0ffp0lStXzuW3+n369NH8+fM1ZMgQDRw4UNHR0ZowYYL69Onj8iGcuPNy0+dy5cqpZ8+emjBhgqxWq4KCgjRjxgyVKFFCffr0ce6LPhcOZ86c0ZgxY9S5c2dVrVpVcXFxWrRokfbv368pU6Y4x+W27zAn3o9Fz1NPPaWmTZsqLCxMkvT1119ryZIleuyxx5xT4YYNG6ZRo0apSpUqatq0qdauXat9+/ZpwYIFBVk6riElJUWbNm2SdPV7c2JiovP/4CZNmqhUqVK56mlERIQiIyM1btw4vfDCCypWrJjeffddhYWFqV27dgXy3PCHG/U5KipKs2fP1gMPPKCKFSvq/Pnzmjt3ri5cuKBJkyY591NY+2wxjGt8fDfyZPny5Ro7dmyO6w4dOiRJ+uabbzRjxgwdP35cSUlJCggIUOvWrTVixAiVLVvWZZtjx47p1Vdf1d69e+Xr66vu3btr5MiR/GavgOWmz5KUlpamd999V6tWrVJSUpIaNGig8ePHZ7u+iT6b3+XLlzV27FgdOHBAly5dkoeHh+rUqaNnnnnG5aYEUu77DnPi/Vi0vPbaa9qyZYvOnTunzMxMVatWTb169VK/fv1cpj59+umnmjVrls6ePavq1avrueee03333VeAleNaTp8+rfvvvz/HdfPmzVPTpk0l5a6nCQkJev311/XVV18pIyNDkZGRGj9+PL+UMYEb9blcuXJ65ZVXdOjQIV2+fFne3t6KiIjQ0KFDVa9ePZfxhbHPhDQAAAAAMBGuSQMAAAAAEyGkAQAAAICJENIAAAAAwEQIaQAAAABgIoQ0AAAAADARQhoAAAAAmAghDQAAAABMhJAGAChSpkyZorCwsIIu45adPn1aYWFhWr58eUGXAgC4w+wFXQAAANeyfPlyjR071vnY09NT/v7+CgsL0z333KMePXqoePHiBVhh0RQVFaVPPvlE+/bt0y+//KK0tDR9/fXXqlSpUkGXBgBuwWIYhlHQRQAAkJOskDZ8+HBVqlRJGRkZunjxor777jtt27ZNFSpU0HvvvaeaNWs6t8nIyJDD4VCxYsUKsPJbZxiG0tLSZLfbZbPZ7uixly9frhdffFE1atSQzWbTwYMHCWkAcAdxJg0AYHqtW7dW3bp1nY8HDhyoHTt2aNCgQRo8eLDWrl0rLy8vSZLdbpfdXvj/e7NYLAUWNNu0aaPdu3erePHimjNnjg4ePFggdQCAu+KaNABAodS8eXMNHjxYZ86c0erVq53Lc7omLSwsTK+88oq++OILderUSfXq1VPv3r116NAhSdInn3yiBx54QHXr1lW/fv10+vTpbMf76aef9NRTT6lhw4aqX7+++vbtq++//95lTNaxf/vtN40ZM0aNGjVSw4YNNXbsWKWkpLiM3bZtmx555BE1atRIERERat++vf7v//7Puf5a16Tt2LFDjz76qMLDw9WoUSM9++yzOnbsWJ7ryEnJkiWZRgoABYiQBgAotLp37y5J2rp16w3H7tmzR2+++aYefPBBDR06VMeOHdOgQYP08ccfa/78+Xr00Uf11FNPae/evRo3bpzLtjt27NDf//53JSUlaejQoRo5cqTi4+P1+OOPa9++fdmONWLECCUlJem5555Tx44dtXz5ck2dOtW5/siRIxo4cKDS0tI0fPhwvfDCC2rTpo1++OGH6z6H7du36+mnn9alS5c0dOhQ9e/fX3v37tUjjzySY7C8UR0AAHMq/PNBAABuq1y5cipRooROnTp1w7HHjx/XF1984byuyt/fXy+99JLef/99rVu3znnmKDMzUzNmzNDp06dVqVIlGYahl19+WU2bNtXs2bNlsVgkSX369FHnzp01ceJEffDBBy7HqlWrlv73v/85H1++fFlLly7VP//5T0lXz6Klp6dr1qxZKlWqVK6f74QJE+Tv76/FixerZMmSkqS2bdvqoYce0pQpU/Tmm2/eVB0AAHPiTBoAoFDz8fFRUlLSDcc1b97c5cYX9evXlyS1a9fOZWpfvXr1JMkZ/A4ePKgTJ06oa9euio2NVUxMjGJiYpScnKzmzZtr9+7dyszMdDlWnz59XB43atRIly9fVmJioiTJz89PkvT1119n2/Zazp8/r4MHD+qhhx5yBjRJqlmzplq0aKFNmzZl2+ZGdQAAzIkzaQCAQi05OVmlS5e+4bjy5cu7PM4KZuXKlXNZXqJECUlSfHy8JOnEiROSpBdeeOGa+05ISJC/v7/zcYUKFVzWZ4WyuLg4FS9eXJ06ddKnn36q8ePH65133lHz5s31wAMPqEOHDrJac/796dmzZyVJ1atXz7YuJCREW7duVXJysnx8fHJdBwDAnAhpAIBC69y5c0pISFCVKlVuOPZat7G/1vKsT6jJ+nv06NGqVatWjmP/HIwkXTNoZe3Ly8tLH3/8sXbt2qWNGzdqy5YtWrt2rRYvXqwPPvgg3265f6M6AADmREgDABRaq1atkiRFRkbetmNUrlxZ0tUzby1atMi3/VqtVjVv3lzNmzfX2LFjNX36dL377rvatWtXjsfJOit2/PjxbOuioqIUEBCQLSwCAAonrkkDABRKO3bs0HvvvadKlSqpW7dut+04derUUZUqVfTBBx/keO1bTEzMTe/z8uXL2ZZlnaVLS0vLcZuyZcuqVq1aWrlypXMqpiQdPnxY27Zt0z333HPTdQAAzIkzaQAA09u8ebOioqLkcDh08eJF7dq1S9u2bVOFChX0/vvv39YPfbZarXrttdc0YMAAdenSRT169FBQUJCio6O1a9cuFS9eXNOnT7+pfU6bNk179uzRPffco4oVK+rSpUtauHChypUrp4YNG15zu9GjR2vAgAHq3bu3evbsqdTUVC1YsEAlSpTQ0KFDb/WpOiUkJGj+/PmS5PxYgI8//lglSpSQn5+f+vbtm2/HAgBkR0gDAJje5MmTJUkeHh4qWbKkQkNDNW7cOPXo0eOO3ACjadOmWrx4sd577z0tWLBAycnJCgwMdH4o9s1q06aNzpw5o2XLlik2NlYBAQFq0qSJhg0b5rxxSU5atGih2bNna/LkyZo8ebLsdrsaN26sf/7zn85pmfkhLi5OkyZNclmW9TEDFStWJKQBwG1mMbh6GAAAAABMg2vSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATISQBgAAAAAmQkgDAAAAABMhpAEAAACAiRDSAAAAAMBECGkAAAAAYCKENAAAAAAwEUIaAAAAAJgIIQ0AAAAATOT/Ac6RSu6ztYdLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "# graphics\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# display matplotlib graphics in notebook\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "# Liste des mots de words_plus_neighbors\n",
        "mots_words_plus_neighbors = [item[0] for item in words_plus_neighbors]\n",
        "\n",
        "# Indices des mots de words_plus_neighbors dans la liste complète de mots\n",
        "indices_mots = [mots.index(mot) for mot in mots_words_plus_neighbors]\n",
        "\n",
        "# Extraire les embeddings correspondants aux mots de words_plus_neighbors\n",
        "word_vectors = embeddings[indices_mots]\n",
        "\n",
        "# Afficher le tableau de vecteurs\n",
        "print(word_vectors)\n",
        "\n",
        "tSNE = TSNE(random_state=0, n_iter=2000, perplexity=5.0)\n",
        "\n",
        "T = tSNE.fit_transform(word_vectors)\n",
        "\n",
        "df = pd.DataFrame(T, columns=['Dimension 1', 'Dimension 2'])\n",
        "\n",
        "# Visualisation avec seaborn\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(x='Dimension 1', y='Dimension 2', data=df)\n",
        "\n",
        "# Ajouter les labels des mots avec plt.annotate\n",
        "for i, mot in enumerate(mots_words_plus_neighbors):\n",
        "    plt.annotate(mot, (T[i, 0], T[i, 1]), fontsize=8, alpha=0.7)\n",
        "\n",
        "plt.title('Visualisation t-SNE des word_vectors en 2D')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNQPVKDuhf4r"
      },
      "source": [
        "## 3. Evaluation des embeddings\n",
        "\n",
        "### Évaluation intrinsèque\n",
        "\n",
        "[A Survey of Word Embeddings Evaluation Methods](https://arxiv.org/pdf/1801.09536.pdf), Bakarov, 2018.\n",
        "\n",
        "\n",
        ">les distances entre les mots dans un espace vectoriel pourraient être évaluées à l'aide des jugements heuristiques humains sur les distances sémantiques réelles entre ces mots (par exemple, la distance entre tasse et gobelet définies dans un intervalle continu 0, 1 serait 0.8 puisque ces mots sont synonymes, mais pas vraiment la même chose).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M26StShYhf4r"
      },
      "source": [
        "### Téléchargement des datasets pré-établis et annotés manuellement\n",
        "\n",
        "Nous allons utiliser 4 jeux de données  pour évaluer la qualité des embeddings : [MEN](http://clic.cimec.unitn.it/~elia.bruni/MEN.html), [WS353R](http://www.aclweb.org/anthology/N09-1003.pdf), [SimLex999](http://leviants.com/ira.leviant/MultilingualVSMdata.html) et [MTurk](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.205.8607&rep=rep1&type=pdf).\n",
        "\n",
        "\n",
        "Ces jeux de données contiennent des paires de mots dont la proximité sémantique a été évaluée manuellement par des humains. Pour chaque dataset, dataset.X contient une liste de paires de mots et dataset.y contient le score de proximité pour chaque paire.\n",
        "\n",
        "* MEN, 3 000 paires évaluées par relation sémantique avec une échelle discrète de 0 à 50\n",
        "* SimLex-999, 999 paires évaluées avec un fort respect pour la similarité sémantique avec une échelle de 0 à 10\n",
        "* MTurk-287, 287 paires évaluées par relation sémantique avec une échelle de 0 à 5\n",
        "* WordSim-353, 353 paires évaluées par similarité sémantique (cependant, certains chercheurs trouvent les instructions pour les évaluateurs ambiguës en ce qui concerne la similarité et l'association) sur une échelle de 0 à 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "bU_zl0oMhf4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "7e8d9734-f50c-4500-aac1-b78368a3208b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'similarity' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-538fa415d8cd>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m similarity_tasks = {\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m\"MEN\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_MEN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"WS353R\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_WS353\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relatedness\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"SimLex999\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_SimLex999\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'similarity' is not defined"
          ]
        }
      ],
      "source": [
        "# custom functions\n",
        "\n",
        "similarity_tasks = {\n",
        "    \"MEN\": similarity.fetch_MEN(),\n",
        "    \"WS353R\": similarity.fetch_WS353(which=\"relatedness\"),\n",
        "    \"SimLex999\": similarity.fetch_SimLex999(),\n",
        "    \"MTurk\": similarity.fetch_MTurk(),\n",
        "}\n",
        "\n",
        "for name, dataset in similarity_tasks.items():\n",
        "    print('\\n', name, ':',len(dataset.X),'items')\n",
        "    for data, score in zip(dataset.X[:4], dataset.y[:4]):\n",
        "        print(' '*4, ', '.join(data), ':', score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pK_P-tMxfQ0",
        "outputId": "c70c2580-370f-4d65-def2-6e6e0765ecbd"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting similarity\n",
            "  Downloading similarity-0.0.1-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from similarity) (0.6.2)\n",
            "Collecting jellyfish (from similarity)\n",
            "  Downloading jellyfish-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from similarity) (1.25.2)\n",
            "Collecting interaction (from similarity)\n",
            "  Downloading interaction-1.3-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: jellyfish, interaction, similarity\n",
            "Successfully installed interaction-1.3 jellyfish-1.0.3 similarity-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EMxXBkOhf4s"
      },
      "source": [
        "### Résultats évaluation intrinsèque\n",
        "\n",
        "Notre objectif est de comparer les similarités entre les paires de mots des datasets calculées à partir des embeddings et celles données par les annotateurs humains. Si un embedding prédit les similarités de la même manière que les humains, on estime qu'il est bon. On peut donc calculer la corrélation entre la proximité donné par l'embedding et celle donnée par les humains pour chaque paire de mots du dataset.\n",
        "\n",
        "Pour cet excercice, nous allons utiliser  le classe [Embeddings](https://polyglot.readthedocs.io/en/latest/polyglot.mapping.html#module-polyglot.mapping.embeddings) de polyglot. Pour charger un embeddind avec cette classe :\n",
        "\n",
        "`glove_embeddings =  Embedding.from_glove('data/glove.6B.50d.txt')`\n",
        "\n",
        "Pour pouvoir charger les embeddings de Collobert de la même manière, il faut mettre les mots et les vecteurs dans un seul fichier, par exemple avec la commande linux `paste`:\n",
        "\n",
        "`paste -d ' ' collobert_words.lst collobert_embeddings.txt > collobert.txt`\n",
        "\n",
        "\n",
        "\n",
        "#### Question\n",
        "\n",
        "> * pour chaque embedding Collober et Glove, et chaque dataset (MEN, WS353R, SimLex999 et MTurk), calculer la similarité entre les proximités données par l'embedding et celles données par les humains. On utilisera la fonction `similarity.evaluate_similarity(word_embeddings, dataset.X, dataset.y)` qui renvoit le [coefficient de correlation de Spearman](https://fr.wikipedia.org/wiki/Corr%C3%A9lation_de_Spearman).\n",
        "> * stocker les scores  pour chaque embedding et chaque dataset dans une liste `similarity_results = []` sous forme d'un dictonnaire : `similarity_results.append({'Embeddings': embeddings_name, 'Dataset': name, 'Score': score})`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "wiuNiBGahf4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "444605d0-3b2e-4e2f-f1f3-ae3a00f9340b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-65-23ad8e6aa5f0>, line 15)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-23ad8e6aa5f0>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "# embedding functions\n",
        "from polyglot.mapping import Embedding\n",
        "\n",
        "similarity_results = []\n",
        "\n",
        "# Load both embeddings with Embedding.from_glove from Polyglot\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Loop on embeddings\n",
        "for embeddings_name, embeddings in [('collobert', collobert_embeddings), ('glove', glove_embeddings)]:\n",
        "    # loop on tasks\n",
        "    for name, dataset in similarity_tasks.items():\n",
        "        # compute similarity\n",
        "        # YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upAVOXWNhf4s"
      },
      "source": [
        "### Visualisation des résultats de similarité\n",
        "\n",
        "Le code suivant permet de visualiser les coefficients de corrélation pour chaque dataset sur les différents jeux de test.\n",
        "\n",
        "#### Question\n",
        "> * Quel est selon ces métriques le meilleur embedding ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4ag7UTlhf4s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.DataFrame.from_dict(similarity_results, orient='columns')\n",
        "df\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.patch.set_facecolor('#f9f9f9')\n",
        "\n",
        "\n",
        "\n",
        "sns.set(rc={'figure.figsize':(8, 6)})\n",
        "sns.set(font_scale=1)\n",
        "\n",
        "colors = [\"#e74c3c\", \"#75d9fc\", \"#b4e0ef\", \"#34495e\", \"#e74c3c\", \"#2ecc71\"]\n",
        "ax = sns.barplot(x=\"Dataset\", y=\"Score\", hue=\"Embeddings\", data=df, errwidth=0, palette=sns.color_palette(colors))\n",
        "\n",
        "\n",
        "ax.legend(loc=9, bbox_to_anchor=(0.5, -0.1), ncol=3, fancybox=True, shadow=False)\n",
        "ax.set(xlabel=\"\", ylabel=\"\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AllDtUShf4t"
      },
      "source": [
        "## Évaluation d'analogies\n",
        "\n",
        "Notre objectif est maintenant d'explorer les relations sémantiques induites par l'arithmétique sur les embeddings. Nous allons donc explorer les analogies induites par les embeddings sous forme de raisonnement du type : \"l'homme est au roi ce que la femme est à ?\", la réponse étant \"la reine\". On peut calculer la réponse avec les représentations fournies par l'embedding par :  \n",
        "\n",
        "`v = vecteur(roi)-vecteur(homme)+vecteur(femme)`.\n",
        "\n",
        "La réponse étant alors le mot dont la représentation est la plus proche du vecteur `v`. Pour trouver le mot dont le vecteur est le plus proche de `v`, il faut définir une distance dans l'espace des embeddings. Nous utiliserons la [similarité cosinus](https://fr.wikipedia.org/wiki/Similarit%C3%A9_cosinus)\n",
        "\n",
        "#### Question\n",
        ">* Implémenter la similarity cosinus à l'aide des fonctions [np.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html#numpy.dot) et [np.linalg.norm](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html#numpy.linalg.norm)\n",
        ">* Appliquer le calcul d'analogies sur les triplets proposés ou ceux de votre choix. Observez-vous [ce phénomène](https://arxiv.org/pdf/1607.06520.pdf) ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKdFZIXHhf4t"
      },
      "outputs": [],
      "source": [
        "def my_cosine_similarity(a,b):\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "def sorted_by_similarity(word_embeddings, base_vector):\n",
        "    \"\"\"Returns words sorted by cosine distance to a given vector, most similar first\"\"\"\n",
        "    words_with_distance = [(my_cosine_similarity(base_vector, word_embeddings[w]), w)\n",
        "                           for w in word_embeddings.vocabulary]\n",
        "\n",
        "    return sorted(words_with_distance, key=lambda t: t[0], reverse=True)\n",
        "\n",
        "def is_redundant(word):\n",
        "    return (\n",
        "        word_1.lower() in word.lower() or\n",
        "        word_2.lower() in word.lower() or\n",
        "        word_3.lower() in word.lower())\n",
        "\n",
        "\n",
        "pairs = [(['man', 'woman'], 'king'),\n",
        "         (['man', 'programmer'], 'woman'),\n",
        "         (['father', 'doctor'], 'mother'),\n",
        "         (['father', 'facebook'], 'mother')\n",
        "        ]\n",
        "\n",
        "words_and_responses = []\n",
        "\n",
        "# Note : you may need to update the following line with your Polyglot Embeddings\n",
        "for embeddings_name, embeddings in [('collobert', collobert_embeddings), ('glove', glove_embeddings)]:\n",
        "    for pair in pairs:\n",
        "        word_1, word_2, word_3 = pair[0][0], pair[0][1], pair[1]\n",
        "\n",
        "        closest = sorted_by_similarity(embeddings,\n",
        "                                       embeddings[word_2] - embeddings[word_1] +\n",
        "                                       embeddings[word_3])[:10]\n",
        "\n",
        "        closest = [(dist, w) for (dist, w) in closest if not is_redundant(w)] #\n",
        "\n",
        "        print(\"{} + {} - {} = ? {}\".format(word_2, word_3, word_1, closest[0][1]))\n",
        "        words_and_responses += [word_1, word_2, word_3,closest[0][1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D9XlDuChf4t"
      },
      "source": [
        "### Visualisation des analogies\n",
        "\n",
        "Les relations d'analogies peuvent se visualiser dans l'espace des embeddings après réduction de dimension, par exemple avec tSNE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G4GgQUOhf4t"
      },
      "outputs": [],
      "source": [
        "# Note : you may need to update the following line with your Polyglot Embeddings\n",
        "for embeddings_name, embeddings in [('collobert', collobert_embeddings), ('glove', glove_embeddings)]:\n",
        "\n",
        "    word_vectors = np.array([embeddings[word] for word in words_and_responses[:4]])\n",
        "\n",
        "    tsne = TSNE(n_components=2, random_state=0, n_iter=1000, perplexity=3.0)\n",
        "    np.set_printoptions(suppress=True)\n",
        "    T = tsne.fit_transform(word_vectors)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    fig.patch.set_facecolor('#f9f9f9')\n",
        "\n",
        "    sns.set(rc={'figure.figsize':(6, 6)})\n",
        "    sns.set(font_scale=1.3)\n",
        "\n",
        "    sns.scatterplot(x=T[:, 0], y=T[:, 1])\n",
        "\n",
        "    for label, x, y in zip(words_and_responses, T[:, 0], T[:, 1]):\n",
        "        plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us2iR_Xdhf4t"
      },
      "source": [
        "## Evaluation des embeddings de BERT\n",
        "\n",
        "BERT a été un des premiers modèles de langue Transformer, entraînés sur de gros corpus, disponible librement. De nombreux modèles sont disponibles sur HuggingFace.\n",
        "\n",
        "Comme BERT est un modèle contextuel, il est nécessaire de lui faire prédire des phrases entières pour étudier les embeddings de mots qu'il produit. Dans cette section, nous allons comparer les embeddings obtenus pour des mots polysémiques en fonction de la phrase dans laquelle ils sont utilisés.\n",
        "\n",
        "En anglais, *plant* possède deux sens : celui d'usine et celui d'un végétal. Avec un embedding non contextuel, de type Glove ou Colobert, ces deux sens du mot plus sont associés à un identique embedding. Avec BERT, nous allons voir que le même mot peut avoir plusieurs embeddings en fonction du contexte.\n",
        "\n",
        "First, load the BERT model and tokenizer from HuggingFace :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r31XmPrYhf4u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# Load pre-trained model\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # to access the hidden states\n",
        "                                  )\n",
        "# set the model to \"evaluation\" mode\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqtTAppxhf4u"
      },
      "source": [
        "### Tokenizer\n",
        "\n",
        "Les modèles de langues sont entrainés avec un découpe spécifique des phrases en token. Ces tokens peuvent être des mots ou des parties de mots. Il est nécessaire d'utiliser le tokenizer correspondant à chaque model.\n",
        "\n",
        "tokenizer.vocab.keys() donne la liste de tous les tokens connus du modèle de langue.\n",
        "\n",
        "#### Question\n",
        ">* combien de token différents sont connu du tokenizer de BERT ?\n",
        ">* affichez une centaine de token aléatoirement. Que constatez-vous ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihIJSQC4hf4u"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# number of token in tokenizer\n",
        "# YOU CODE HERE\n",
        "# sample of 100 tokens\n",
        "# YOU CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djt9lkBrhf4u"
      },
      "source": [
        "Le tokenizer découpe les phrases et transforme les éléments (mots ou sous-mots) en indice.\n",
        "\n",
        "BERT peut traiter plusieurs phrases mais il faut lui indiquer le découpage en phrases (segment) avec un indice : 0 pour la première phrases, 1 pour la deuxième.\n",
        "\n",
        "Deux tokens spécifiques doivent être aussi ajoutés :\n",
        "* [CLS], un token spécifique utilisé pour la classification de phrase\n",
        "* [SEP], le token de fin de phrase.\n",
        "\n",
        "#### Question\n",
        ">* Appliquer la fonction bert_tokenize sur les 3 phases et conservez les 3 vecteurs (index, token, segment)\n",
        ">* Affichez ces informations pour chacune des phrases et vérifier que le mot *plant* a bien le même indice de token dans les deux phrases où il apparait."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2k-oghuhf4u"
      },
      "outputs": [],
      "source": [
        "snt1 = \"The plant has reached its maximal level of production.\"\n",
        "snt2 = \"The cars are assembled inside the factory.\"\n",
        "snt3 = \"A plant needs sunlight and water to grow well.\"\n",
        "\n",
        "\n",
        "def bert_tokenize(snt):\n",
        "    \"\"\" Apply the BERT tokenizer to a list of words representing a sentence\n",
        "        and return 3 lists:\n",
        "        - list of token indx\n",
        "        - list of token for debugging, not used by the BERT model\n",
        "        - list of sentence index\n",
        "        \"\"\"\n",
        "    # Add the special tokens.\n",
        "    tagged_snt = \"[CLS] \" + snt + \" [SEP]\"\n",
        "    # Tokenize\n",
        "    tokenized_snt = tokenizer.tokenize(tagged_snt)\n",
        "    # convert tokens to indices\n",
        "    indexed_snt = tokenizer.convert_tokens_to_ids(tokenized_snt)\n",
        "    # mark the words in sentence.\n",
        "    segments_ids = [1] * len(tokenized_snt)\n",
        "\n",
        "    return (indexed_snt, tokenized_snt, segments_ids)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCPgANNwhf4u"
      },
      "source": [
        "## Inférence\n",
        "\n",
        "Pour calculer les embeddings, il est nécessaire de faire une prédiction avec le modèle BERT sur une phrase complète. La fonction *predict_hidden* convertit les listes d'indices de token et de segment en tenseur pytorch et applique le modèle.\n",
        "\n",
        "Le modème utilisé est un modèle à 12 couches. Nous allons utiliser la dernière couche caché du modèle comme embedding pour représenter les mots. D'autres solutions serait possible, comme une concaténation ou une moyene de plusieurs couches.\n",
        "\n",
        "\n",
        "#### Question\n",
        ">* Appliquer le modèle à chacune des 3 phrases et stocker les embeddings obtenus (tenseurs)\n",
        ">* Afficher la dimension des tenseurs obtenus. Quelle est la dimension du vecteur d'embedding pour chaque mot ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ22ga1nhf4u"
      },
      "outputs": [],
      "source": [
        "\n",
        "def predict_hidden(indexed_snt, segments_ids):\n",
        "    \"\"\"Apply the BERT model to the input token indices and segment indices\n",
        "        and return the last hidden layer\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # Convert inputs to PyTorch tensors\n",
        "        tokens_tensor = torch.tensor([indexed_snt])\n",
        "        segments_tensors = torch.tensor([segments_ids])\n",
        "        outputs = model(tokens_tensor, segments_tensors)\n",
        "        hidden_states = outputs[2]\n",
        "        one_hidden_layer = hidden_states[12][0]\n",
        "\n",
        "    return one_hidden_layer\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGDv9ZPthf4v"
      },
      "source": [
        "La couche cachée renvoyée par la fonction *predict_hidden* est un tenseur contenant pour chaque token de la phrase d'entrée un vecteur contextuel le représentant. On peut utiliser ce vecteur pour représenter le sens de ce mot en fonction de son contexte. Nous allons comparer la représentation du mot polysémique *plant* en fonction de son contexte.\n",
        "\n",
        "#### Question\n",
        ">* En utilisant la [distance cosinus](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html), calculer les distances suivantes:\n",
        ">   * distance entre *plant* dans la phrase 1 (plant-factory) et *plant* dans la phrase 3 (plant-vegetal)\n",
        ">   * distance entre *plant* dans la phrase 1 (plant-factory) et *factory* dans la phrase 2\n",
        ">   * distance entre *plant* dans la phrase 1 (plant-factory) et *production* dans la phrase 2\n",
        ">   * distance entre *plant* dans la phrase 3 (plant-vegetal) et *production* dans la phrase 2\n",
        "> * Comment interprêter ces distances ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wni0J6FGhf4v"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# YOUR CODE HERE\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp-emb",
      "language": "python",
      "name": "nlp-emb"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}